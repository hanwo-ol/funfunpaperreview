### 1. 기본 개념: 경사 하강법 (Gradient Descent)

모델을 최적화하는 가장 기본적인 방법은 경사 하강법입니다. 이 방법은 손실 함수(Loss Function)의 값을 최소화하는 모델 파라미터를 찾는 과정입니다.

#### 1.1. 경사 하강법의 수식

경사 하강법의 파라미터 업데이트 규칙은 다음과 같은 수식으로 표현됩니다.

$$
\theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(\theta_t)
$$

#### 1.2. 표기법(Notation) 정의 및 설명

*   **$\theta_t$**: 최적화의 $t$번째 단계(step)에서의 모델 파라미터(parameter) 벡터입니다.
*   **$\theta_{t+1}$**: $t$번째 단계 이후 업데이트된 새로운 모델 파라미터 벡터입니다.
*   **$L(\theta_t)$**: 파라미터 $\theta_t$를 사용하는 모델의 손실 함수(Loss Function) 값입니다. 이 값을 최소화하는 것이 목표입니다.
*   **$\nabla_{\theta} L(\theta_t)$**: 손실 함수 $L$을 파라미터 $\theta$에 대해 편미분한 그래디언트(gradient) 벡터입니다. 이 벡터는 손실 함수 값이 가장 가파르게 증가하는 방향을 가리킵니다.
*   **$\eta$**: 학습률(learning rate)이라고 불리는 스칼라(scalar) 값의 하이퍼파라미터(hyperparameter)입니다. 파라미터를 업데이트할 보폭(step size)의 크기를 결정합니다.

#### 1.3. 수식의 연산 설명

1.  **$\nabla_{\theta} L(\theta_t)$ 계산**: 현재 파라미터 $\theta_t$에서 손실 함수의 그래디언트를 계산합니다.
2.  **방향 및 크기 조절**: 그래디언트 벡터( $\nabla_{\theta} L(\theta_t)$ )는 손실이 가장 크게 증가하는 방향입니다. 이 벡터에 음수 부호(-)를 붙여 손실이 가장 크게 감소하는 방향으로 전환합니다.
3.  **학습률 적용**: 손실 감소 방향 벡터에 학습률 $\eta$를 곱하여 업데이트할 크기를 조절합니다.
4.  **파라미터 업데이트**: 현재 파라미터 $\theta_t$에서 위에서 계산된 업데이트 벡터( $\eta \nabla_{\theta} L(\theta_t)$ )를 빼서 다음 단계의 파라미터 $\theta_{t+1}$을 구합니다.

이 과정을 손실 값이 충분히 작아질 때까지 반복하여 최적의 파라미터 $\theta$를 찾습니다.

---

### 2. 핵심 아이디어: 학습을 통해 최적화기(Optimizer) 만들기

기존 경사 하강법은 고정된 규칙($-\eta \nabla_{\theta} L$)에 따라 파라미터를 업데이트합니다. 여기서 더 나아가, **최적의 업데이트 규칙 자체를 학습**할 수는 없을까요?

이 아이디어는 기존의 고정된 최적화 알고리즘을 학습 가능한 모델로 대체하는 것입니다. 본 자료에서는 이 학습 가능한 모델로 **순환 신경망(Recurrent Neural Network, RNN)** 을 사용합니다.

#### 2.1. 용어 정의

*   **Optimizee (피최적화 모델)**: 우리가 최적화하고자 하는 대상 모델(예: 이미지 분류를 위한 CNN). 이 모델을 '베이스 네트워크(Base Network)'라고도 합니다.
*   **Optimizer (최적화 모델)**: Optimizee의 파라미터를 어떻게 업데이트할지 결정하는 모델. 여기서는 RNN이 이 역할을 수행합니다.

즉, **RNN(Optimizer)이 베이스 네트워크(Optimizee)를 위한 최적의 파라미터 업데이트 방법을 학습**합니다.

---

### 3. 경사 하강법으로 경사 하강법 학습하기

이 알고리즘의 이름이 의미하는 바는 다음과 같습니다.

1.  **"학습 대상"**: 경사 하강법과 같은 최적화 과정을 학습합니다. 이 학습은 **RNN(Optimizer)**을 통해 이루어집니다.
2.  **"학습 방법"**: 이 RNN(Optimizer) 자체를 훈련시키는 방법으로 **경사 하강법**을 사용합니다.

#### 3.1. 전체 프로세스

아래 다이어그램은 Optimizer와 Optimizee 간의 상호작용을 보여줍니다.

```
                  +---------------------+
                  | Optimizer (RNN)     |
                  | 파라미터: φ         |
                  +---------------------+
                         |           ^
업데이트된 파라미터 θ_t+1 |           | 손실 값 L(θ_t)
                         v           |
                  +---------------------+
                  | Optimizee (Base Net)|
                  | 파라미터: θ         |
                  +---------------------+
```

1.  **Optimizer(RNN)**는 **Optimizee**를 위한 업데이트된 파라미터를 계산하여 전달합니다.
2.  **Optimizee**는 전달받은 파라미터를 사용하여 예측을 수행하고, 실제 값과의 차이를 통해 손실(loss)을 계산합니다.
3.  계산된 손실 값은 **Optimizer(RNN)**에게 다시 전달됩니다.
4.  **Optimizer(RNN)**는 이 손실 정보를 바탕으로 **자기 자신의 파라미터(φ)를 경사 하강법으로 업데이트**하여, 다음 번에 더 나은 파라미터 업데이트를 제안할 수 있도록 스스로를 개선합니다.

#### 3.2. Optimizer(RNN)의 손실 함수

Optimizer의 목표는 Optimizee의 손실을 최소화하는 것입니다. 따라서 Optimizer의 손실 함수 $L(\phi)$는 Optimizee가 특정 태스크($f$) 모음 전체에 대해 달성하는 평균 손실로 정의할 수 있습니다.

$$
L(\phi) = \mathbb{E}_{f}[f(\theta(f, \phi))]
$$

*   **$L(\phi)$**: Optimizer(RNN)의 손실 함수. Optimizer의 파라미터 $\phi$에 의해 결정됩니다.
*   **$\phi$**: Optimizer(RNN) 모델의 학습 가능한 파라미터(가중치, 편향 등) 벡터입니다.
*   **$\mathbb{E}_{f}$**: 여러 다른 태스크 또는 데이터셋 $f$에 대한 기댓값(평균)을 의미합니다. 이는 Optimizer가 특정 문제 하나에만 과적합되지 않고, 범용적인 최적화 성능을 갖도록 하기 위함입니다.
*   **$f(\theta(f, \phi))$**: 태스크 $f$에 대한 Optimizee의 최종 손실 값입니다.
*   **$\theta(f, \phi)$**: 파라미터 $\phi$를 가진 Optimizer에 의해 최적화가 끝난 후의 Optimizee 파라미터입니다.

이 손실 함수 $L(\phi)$를 최소화하기 위해, 우리는 $\phi$에 대한 그래디언트 $\nabla_{\phi} L(\phi)$를 계산하고 경사 하강법을 적용하여 $\phi$를 업데이트합니다.

---

### 4. RNN 기반 Optimizer의 상세 동작 과정

이제 RNN이 구체적으로 어떻게 파라미터 업데이트를 생성하는지 수식을 통해 살펴보겠습니다.

#### 4.1. RNN Optimizer의 입출력 관계

RNN Optimizer를 함수 $m$으로 표현할 때, $t$ 시점에서의 동작은 다음과 같습니다.

$$
(g_t, h_{t+1}) = m(\nabla_t, h_t, \phi)
$$

*   **입력 (Inputs)**:
    *   **$\nabla_t$**: $t$ 시점에서 **Optimizee**의 파라미터 $\theta_t$에 대한 손실 함수의 그래디언트입니다. 즉, $\nabla_t = \nabla_{\theta} f(\theta_t)$ 입니다.
    *   **$h_t$**: $t$ 시점에서 **Optimizer(RNN)**의 은닉 상태(hidden state) 벡터입니다. 이는 과거의 그래디언트 및 업데이트 정보를 요약한 '메모리' 역할을 합니다.
    *   **$\phi$**: Optimizer(RNN) 자체의 파라미터입니다.

*   **출력 (Outputs)**:
    *   **$g_t$**: Optimizer(RNN)가 생성한 **Optimizee**를 위한 파라미터 업데이트 벡터입니다. 이는 기존 경사 하강법의 $- \eta \nabla_t$ 부분을 대체합니다.
    *   **$h_{t+1}$**: 다음 시점($t+1$)으로 전달될 Optimizer(RNN)의 새로운 은닉 상태 벡터입니다.

#### 4.2. Optimizee 파라미터 업데이트

Optimizer(RNN)가 업데이트 벡터 $g_t$를 생성하면, Optimizee의 파라미터는 다음과 같이 매우 간단하게 업데이트됩니다.

$$
\theta_{t+1} = \theta_t + g_t
$$

*   **$\theta_t$**: $t$ 시점의 Optimizee 파라미터.
*   **$g_t$**: RNN이 생성한 업데이트 벡터.
*   **$\theta_{t+1}$**: 업데이트된 $t+1$ 시점의 Optimizee 파라미터.

#### 4.3. 전체 프로세스 다이어그램

아래 다이어그램은 한 타임스텝($t$)에서 다음 타임스텝($t+1$)으로의 정보 흐름을 보여줍니다.

```
           +-------+      θ_t      +----+      θ_{t+1}      +-------+      θ_{t+2}
Optimizee  | ..... | ------------> | +  | ----------------> | f_{t+1} | ------------>
           +-------+               |    |                   +-------+
                                   ^  ^                         |
                                   |  | g_t                     | ∇_{t+1}
                                   |  |                         v
           +-------+      h_t      +----+      h_{t+1}      +-------+      h_{t+2}
Optimizer  | ..... | ------------> | m  | ----------------> |   m   | ------------>
           +-------+               |    |                   +-------+
                                   ^  ^
                                   |  | ∇_t
                                   |  |
                               +-------+
                               | f_t   |
                               +-------+
```

1.  **$t$ 시점**: Optimizee의 파라미터 $\theta_t$에서 그래디언트 $\nabla_t$를 계산합니다.
2.  **Optimizer 입력**: $\nabla_t$와 Optimizer의 이전 은닉 상태 $h_t$가 RNN 함수 $m$에 입력됩니다.
3.  **Optimizer 출력**: RNN 함수 $m$은 업데이트 벡터 $g_t$와 다음 은닉 상태 $h_{t+1}$을 출력합니다.
4.  **Optimizee 업데이트**: $g_t$가 $\theta_t$에 더해져 새로운 파라미터 $\theta_{t+1}$이 됩니다.
5.  **$t+1$ 시점**: 이 과정이 $\theta_{t+1}$을 가지고 다시 반복됩니다.

---

### 5. 결론

'경사 하강법으로 경사 하강법을 학습'하는 알고리즘은 고정된 규칙을 사용하는 대신, 데이터로부터 최적의 업데이트 규칙을 학습하는 RNN 기반의 Optimizer를 제안합니다.

*   **Optimizee (베이스 네트워크)**는 RNN이 제안하는 업데이트($g_t$)를 받아 자신의 파라미터($\theta$)를 갱신합니다.
*   **Optimizer (RNN)**는 Optimizee의 그래디언트($\nabla_t$)를 입력받아 최적의 업데이트($g_t$)를 출력하며, 이 과정 전체에서 발생한 Optimizee의 최종 손실을 줄이는 방향으로 자기 자신의 파라미터($\phi$)를 **경사 하강법**을 통해 학습합니다.

이러한 메타 러닝 접근법을 통해, 특정 문제 도메인에 더 특화되고 효율적인 최적화 방법을 자동으로 발견할 수 있습니다.
