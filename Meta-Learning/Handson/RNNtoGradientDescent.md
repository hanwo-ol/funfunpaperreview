## ✅ 1. 수식의 의미 — 옵티마이저의 목표

기본 네트워크(Optimizee)의 파라미터를 ( \theta ),
RNN 옵티마이저의 파라미터를 ( \phi )라고 할 때,
메타 옵티마이저의 목표는 다음 손실을 최소화하는 것입니다.

[
L(\phi) = \mathbb{E}_f [f(\theta(f, \phi))]
]

* ( f ): base network (optimizee)의 손실 함수
* ( \theta(f, \phi) ): RNN 옵티마이저에 의해 업데이트된 파라미터
* ( L(\phi) ): 여러 태스크에 대해 기대 손실 (즉, “RNN이 얼마나 잘 학습시키는가”를 평가하는 메타 손실)

즉, **RNN의 목적은 base network의 평균 손실을 최소화하도록 학습 규칙(업데이트 규칙)을 학습하는 것**입니다.

---

## ✅ 2. RNN 옵티마이저의 입력과 출력 구조

이제 “RNN이 실제로 무엇을 입력받고, 무엇을 출력하느냐”를 살펴봅시다.

RNN 옵티마이저는 다음과 같이 표현됩니다:

[
(g_t, h_{t+1}) = m(\nabla_t, h_t, \phi)
]

여기서 각 항의 의미는 다음과 같습니다:

| 기호                                       | 의미                                       |
| ---------------------------------------- | ---------------------------------------- |
| ( \nabla_t = \nabla_\theta f(\theta_t) ) | Base network의 gradient (손실의 기울기)         |
| ( h_t )                                  | RNN의 hidden state (과거 업데이트 정보, 손실 패턴 저장) |
| ( \phi )                                 | RNN 옵티마이저의 파라미터                          |
| ( g_t )                                  | 옵티마이저의 출력: 파라미터 업데이트 벡터                  |
| ( h_{t+1} )                              | RNN의 다음 hidden state                     |

즉, **RNN은 현재 gradient와 내부 상태를 입력으로 받아,
다음 파라미터 업데이트 방향 ( g_t )를 예측합니다.**

---

## ✅ 3. 파라미터 업데이트 규칙

이제 옵티마이즈(base network)의 파라미터는 이렇게 갱신됩니다:

[
\theta_{t+1} = \theta_t + g_t
]

* ( g_t )는 일반 경사 하강법의 “(-\alpha \nabla_\theta L)”을 대체하는 역할을 합니다.
* 단, ( g_t )는 학습된 함수 ( m(\cdot) )의 출력이므로,
  **고정된 수식이 아니라 데이터 기반으로 학습된 규칙**입니다.

---

## ✅ 4. 학습 과정 (Meta-Optimization Loop)

이 전체 구조를 학습시키는 과정은 두 단계로 이루어집니다:

| 단계             | 설명                                                                                                     |
| -------------- | ------------------------------------------------------------------------------------------------------ |
| **Inner loop** | RNN 옵티마이저 ( m_\phi )를 이용해 base network ( f_\theta )의 파라미터를 여러 step 업데이트함.                              |
| **Outer loop** | Inner loop 수행 후, base network의 최종 손실을 계산하고, 이 손실을 이용해 RNN의 파라미터 ( \phi )를 **gradient descent로 업데이트**함. |

즉, RNN은 **gradient를 입력으로 받지만**,
그 gradient를 단순히 곱하는 것이 아니라 **어떻게 활용할지를 학습**합니다.
결과적으로, “gradient descent로 gradient descent 규칙을 학습하는” 구조가 완성됩니다.

---

## ✅ 5. 핵심 요약

> * RNN은 경사 하강법을 완전히 대체하지 않고, **경사 정보를 입력으로 받아 업데이트 함수를 학습한다.**
> * 파라미터 업데이트는
>   [
>   \theta_{t+1} = \theta_t + g_t, \quad (g_t, h_{t+1}) = m(\nabla_t, h_t, \phi)
>   ]
>   로 표현된다.
> * Outer loop에서 RNN의 파라미터 ( \phi )를 경사 하강법으로 학습시키므로,
>   **“경사 하강법으로 경사 하강법을 학습한다”**는 문장이 정확히 성립한다.

---

