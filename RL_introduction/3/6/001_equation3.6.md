## 식 (3.6) 뜯어보기

### 1. 식 (3.6)

$$p(s', r | s, a) \doteq \Pr\{S_{t+1}=s', R_{t+1}=r | S_t=s, A_t=a\}$$

### 2. 노테이션(Notation)

*   **$S_t, S_{t+1}$ (대문자 S)**: 시간 $t$와 $t+1$ 시점의 **상태(State)를 나타내는 확률 변수**입니다.
*   **$A_t$ (대문자 A)**: 시간 $t$ 시점에 에이전트가 선택한 **행동(Action)을 나타내는 확률 변수**입니다.
*   **$R_{t+1}$ (대문자 R)**: 행동 $A_t$의 결과로 $t+1$ 시점에 받는 **보상(Reward)을 나타내는 확률 변수**입니다.
*   **$s, s'$ (소문자 s)**: 상태 집합 $\mathcal{S}$에 속하는 **구체적인 특정 상태 값**입니다. ($s'$는 다음 상태)
*   **$a$ (소문자 a)**: 행동 집합 $\mathcal{A}(s)$에 속하는 **구체적인 특정 행동 값**입니다.
*   **$r$ (소문자 r)**: 보상 집합 $\mathcal{R}$에 속하는 **구체적인 특정 보상 값**입니다.
*   **$\Pr\{ \cdot \}$**: 중괄호 안의 사건이 일어날 **확률(Probability)** 을 의미합니다.
*   **$|$ (Vertical Bar)**: **조건부 확률(Conditional Probability)**을 나타냅니다. "뒤의 조건($S_t=s, A_t=a$)이 주어졌을 때"라고 해석합니다.
*   **$\doteq$**: "정의상 같다(Defined as)"는 의미입니다. 좌변의 함수 $p$는 우변의 확률로 정의된다는 뜻입니다.

---

### 3. 식의 의미

> **"현재 시점 $t$에 상태가 $s$이고, 여기서 행동 $a$를 선택했다고 가정하자($|$ 뒤의 조건).**
> **이때, 바로 다음 시점 $t+1$에 상태가 $s'$가 되고, 동시에 보상으로 $r$을 받을 확률은 얼마인가?"**

#### 결합 확률 분포 (Joint Probability)
이 함수 $p$는 다음 상태($s'$)와 보상($r$)이 **동시에** 결정되는 확률 분포를 나타냅니다.
*   단순히 "어디로 가는가($s'$)"만 알려주는 것이 아니라, "어디로 가면서 얼마($r$)를 받는가"를 쌍(Pair)으로 알려줍니다.
*   환경의 물리 법칙이나 규칙이 확률적(Stochastic)이라면, 같은 행동을 해도 결과($s', r$)가 매번 다를 수 있는데, 그 가능성을 모두 수치화한 것입니다.

#### 마르코프 속성 (The Markov Property)
식의 오른쪽 조건 부분을 보면 $S_t=s, A_t=a$만 있고, 그 이전의 역사($S_{t-1}, A_{t-1}, \dots$)는 없습니다.
*   이는 **"미래($S_{t+1}, R_{t+1}$)를 예측하는 데 있어, 현재($S_t, A_t$) 정보만으로 충분하다"**는 MDP의 대전제인 마르코프 속성을 수식으로 보여주는 것입니다.

#### 확률의 합은 1
특정 상태 $s$에서 행동 $a$를 했을 때, 일어날 수 있는 모든 결과($s', r$의 모든 조합)의 확률을 더하면 반드시 1이 되어야 합니다.

$$ \sum_{s' \in \mathcal{S}} \sum_{r \in \mathcal{R}} p(s', r | s, a) = 1 $$

---

## 그럼 얘는 뭐냐?

$$ \sum_{s' \in \mathcal{S}} \sum_{r \in \mathcal{R}} p(s', r | s, a) = 1 $$

> **특정 상태 $s$에서 특정 행동 $a$를 취했을 때, 발생 가능한 모든 결과(다음 상태 $s'$와 보상 $r$)에 대한 확률의 총합**을 의미합니다.


---

### 1. 식 (3.6)의 정의 대입
먼저, $p(s', r | s, a)$를 확률 변수의 표기법으로 바꿉니다.

$$ \sum_{s' \in \mathcal{S}} \sum_{r \in \mathcal{R}} p(s', r | s, a) = \sum_{s' \in \mathcal{S}} \sum_{r \in \mathcal{R}} \Pr \{ S_{t+1}=s', R_{t+1}=r \mid S_t=s, A_t=a \} $$

여기서 **조건($S_t=s, A_t=a$)**은 고정된 값입니다. 즉, "에이전트가 $s$에서 $a$를 했다"는 사건이 이미 일어난 상황에서의 확률 분포를 보는 것입니다.

### 2. 주변 확률 분포(Marginal Distribution)로의 전개
이중 합산에서 안쪽의 합($\sum_{r \in \mathcal{R}}$)을 먼저 계산해 봅니다. 

어떤 결합 확률 분포에서 하나의 변수($r$)에 대해 모든 가능한 값을 더하면, 다른 변수($s'$)에 대한 **주변 확률(Marginal Probability)**이 나옵니다.

$$ \sum_{r \in \mathcal{R}} \Pr\{S_{t+1}=s', R_{t+1}=r \mid S_t=s, A_t=a\} = \Pr\{S_{t+1}=s' \mid S_t=s, A_t=a\} $$

이 식의 의미는 다음과 같습니다.
> "상태 $s$에서 행동 $a$를 했을 때, 보상이 얼마인지에 상관없이(**합산 처리**) 다음 상태가 $s'$가 될 확률"

이를 교재에서는 **상태 전이 확률(State-transition probability)**이라 부르며 $p(s' | s, a)$라고 표기하기도 합니다.

### 3. 최종 상태 공간($\mathcal{S}$)에 대한 합산
이제 남은 바깥쪽의 합($\sum_{s' \in \mathcal{S}}$)을 적용합니다.

$$ \sum_{s' \in \mathcal{S}} \left( \Pr\{S_{t+1}=s' \mid S_t=s, A_t=a\} \right) = \sum_{s' \in \mathcal{S}} p(s' \mid s, a) $$

이 식은 "상태 $s$에서 행동 $a$를 했을 때, 다음에 도달할 수 있는 모든 가능한 상태 $s'$에 대한 확률을 모두 더하라"는 뜻입니다.

### 4. 확률의 공리(Axiom of Probability)에 의한 결론
확률론의 기본 원칙에 따라, 어떤 사건이 일어난 후 발생 가능한 **표본 공간(Sample Space) 전체에 대한 확률의 합은 항상 1**입니다.

에이전트가 행동 $a$를 취했다면, 환경은 반드시 어떤 상태 $s' \in \mathcal{S}$로 전이되어야 하며(그것이 자기 자신일지라도), 어떤 보상 $r \in \mathcal{R}$을 주어야 합니다. 

따라서 모든 $s'$와 $r$의 조합에 대해 확률을 더하면:

$$ \sum_{s' \in \mathcal{S}} \sum_{r \in \mathcal{R}} p(s', r | s, a) = 1 $$
