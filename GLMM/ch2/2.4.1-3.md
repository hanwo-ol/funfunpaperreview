### **2.4.1 $I \times J$ 표에서의 오즈비 (Odds Ratios in *I* × *J* Tables)**

**[원문 번역]**

오즈비는 $\binom{I}{2}$개의 행 쌍과 $\binom{J}{2}$개의 열 쌍의 각 조합을 사용할 수 있다. 행 $a$와 $b$, 그리고 열 $c$와 $d$에 대해, 오즈비 $(\pi_{ac}\pi_{bd})/(\pi_{bc}\pi_{ad})$는 직사각형 패턴의 네 셀을 사용한다. 이러한 유형의 오즈비는 $\binom{I}{2}\binom{J}{2}$개가 있다. 이 오즈비들의 집합은 많은 중복된 정보를 포함한다.

$(I-1)(J-1)$개의 **국소 오즈비(local odds ratios)** 부분집합을 고려해보자.

$$ \theta_{ij} = \frac{\pi_{ij}\pi_{i+1, j+1}}{\pi_{i, j+1}\pi_{i+1, j}}, \quad i=1,\dots,I-1, \quad j=1,\dots,J-1 \quad (2.10) $$

그림 2.3은 국소 오즈비가 인접한 행과 인접한 열의 셀들을 사용함을 보여준다. 이 $(I-1)(J-1)$개의 오즈비들은 행 쌍과 열 쌍으로부터 형성된 모든 오즈비들을 결정한다. 예를 들어, 표 2.1에서, 처음 두 열에 대한 표본 국소 오즈비는 2.08이고, 두 번째와 세 번째 열에 대한 것은 1.74이다. 각 경우에서, 더 심각한 결과가 위약 그룹에 더 만연했다. 이 두 오즈비의 곱은 3.63이며, 이것은 첫 번째와 세 번째 열에 대한 오즈비이다.

최소 오즈비 집합에 대한 구성 (2.10)은 유일하지 않다. 또 다른 기본 집합은 다음과 같다.

$$ \alpha_{ij} = \frac{\pi_{ij}\pi_{IJ}}{\pi_{Ij}\pi_{iJ}}, \quad i=1,\dots,I-1, \quad j=1,\dots,J-1 \quad (2.11) $$

이것은 $i$행 $j$열의 셀과 마지막 행, 마지막 열의 셀에 의해 결정되는 직사각형 패턴의 셀들을 사용한다. 그림 2.3이 이를 설명한다.

주변분포 $\{\pi_{i+}\}$와 $\{\pi_{+j}\}$가 주어졌을 때, $\{\pi_{ij}>0\}$일 때, 확률들을 오즈비 집합 (2.10) 또는 (2.11)로 변환하는 것은 정보를 버리지 않는다.

### **2.4.2 연관성 요인 (Association Factors)**

**[원문 번역]**

연관성을 요약하는 다른 유형은 개별 셀에 초점을 맞추고, 변수들이 독립일 경우 우리가 기대하는 것보다 셀에 더 많은 또는 더 적은 대상이 있는지 여부에 초점을 맞춘다. 이를 수행하는 한 가지 방법은 $IJ$개의 **연관성 요인(association factors)**을 사용하는 것이다(Good 1956).

$$ \pi_{ij} / (\pi_{i+}\pi_{+j}) $$

연관성 요인은 특정 주변분포에 대해, 셀 확률이 독립성에 해당하는 확률에 대한 비(ratio)이다. 그 값은 0과 $\min(1/\pi_{i+}, 1/\pi_{+j})$ 사이에 있으며, 기준값 1은 독립성에 해당한다.

어떤 셀들이 독립성으로부터 상당히 다른 확률을 갖는지 조사하는 것은 유익할 수 있다. 예를 들어, 연관성 요인이 2보다 크거나 1/2보다 작을 때, 셀에서의 독립성으로부터의 이탈이 주목할 만하다고 간주할 수 있다.

### **2.4.3 요약 연관성 측도 (Summary Measures of Association)**

**[원문 번역]**

연관성을 기술하는 또 다른 방법은 단일 요약 지수(index)를 사용하는 것이다. 우리는 이를 먼저 명목형 변수에 대해 논의하고, 그 다음 순서형 변수에 대해 논의한다. 명목형 변수에 대한 가장 해석하기 쉬운 지수들은 구간 변수에 대한 R-제곱과 동일한 구조를 갖는다. 그것과 더 일반적인 급내 상관 계수(intraclass correlation coefficient) 및 상관비(correlation ratio)(Kendall and Stuart 1979)는 설명 변수 X가 주어졌을 때, 반응 Y의 주변분포에서 Y의 조건부 분포로 가면서 발생하는 분산의 비례적 감소(proportional reduction in variance)를 기술한다.

$V(Y)$를 Y의 주변분포 $\{\pi_{+j}\}$에 대한 변동(variation)의 측도라고 하고, $V(Y|i)$를 X의 $i$번째 설정에서 Y의 조건부 분포 $\{\pi_{1|i}, \dots, \pi_{J|i}\}$에 대해 계산된 이 측도라고 하자. **변동의 비례적 감소 측도(proportional reduction in variation measure)**는 다음과 같은 형태를 갖는다.

$$ \frac{V(Y) - E[V(Y|X)]}{V(Y)} \quad (2.12) $$

여기서 $E[V(Y|X)]$는 X의 분포에 대해 취해진 조건부 변동의 기댓값이다. X의 주변분포 $\{\pi_{i+}\}$에 대해, $E[V(Y|X)] = \sum_i \pi_{i+} V(Y|i)$이다.

명목형 반응에 대해, Theil(1970)은 변동 측도 $V(Y) = -\sum_j \pi_{+j}\log\pi_{+j}$를 사용하는 지수를 제안했는데, 이는 **엔트로피(entropy)**라고 불린다. 분할표에 대해, 엔트로피의 비례적 감소는 다음과 같다.

$$ U = \frac{\sum_i\sum_j \pi_{ij}\log(\pi_{ij}/\pi_{i+}\pi_{+j})}{-\sum_j \pi_{+j}\log\pi_{+j}} \quad (2.13) $$

이는 **불확실성 계수(uncertainty coefficient)**라고 불린다. 이 값은 0과 1 사이의 값을 갖는다: $U=0$은 X와 Y의 독립성과 동등하다; $U=1$은 각 $i$에 대해 어떤 $j$에 대해 $\pi_{j|i}=1$이라는 의미에서 조건부 변동이 없다는 것과 동등하다.

형태 (2.12)의 다양한 측도들이 $I \times J$ 표의 연관성을 기술한다(연습문제 2.39, 2.40 참조). 그것들의 한 가지 어려움은 얼마나 큰 값이 강한 연관성을 구성하는지에 대한 직관을 개발하는 것이다. 예를 들어, 엔트로피의 30% 감소를 어떻게 해석해야 하는가? 요약 측도들은 다음에 논의될 것처럼, 두 분류가 모두 순서형일 때 해석하기 더 쉽고 더 유용한 것 같다.

---

### **핵심 내용 해설**

$2 \times 2$ 표에서는 단 하나의 오즈비로 연관성을 완벽하게 요약할 수 있었습니다. 하지만 표가 $I \times J$로 커지면, 연관성의 패턴이 훨씬 복잡해지므로 단 하나의 숫자로 모든 정보를 요약하기 어렵습니다. 이 섹션들은 더 큰 표의 연관성을 기술하는 세 가지 다른 접근법을 소개합니다.

#### **2.4.1: 연관성을 여러 개의 오즈비로 분해하기**

*   **아이디어**: 전체 표의 연관성을 여러 개의 $2 \times 2$ 부분표에서 계산된 오즈비들의 집합으로 나타낸다.
*   **문제**: 너무 많은 오즈비가 존재한다($\binom{I}{2}\binom{J}{2}$개). 대부분은 서로 중복된 정보를 담고 있다.
*   **해결책 (최소 기본 집합)**: 전체 연관성 정보를 잃지 않으면서도, 연관성을 완벽하게 기술할 수 있는 최소한의 오즈비 집합이 필요하다.
    1.  **국소 오즈비 (Local Odds Ratios, $\theta_{ij}$)**: 인접한 두 행과 두 열로 만들어진 $2 \times 2$ 표의 오즈비. 총 $(I-1)(J-1)$개가 있으며, 이는 독립성 검정의 자유도와 같다. 이 집합만 있으면 다른 모든 오즈비를 계산할 수 있다. (예: $\theta_{1,3} = \theta_{1,1} \times \theta_{1,2}$)
    2.  **다른 기본 집합 ($\alpha_{ij}$)**: 기준 셀(예: 마지막 행, 마지막 열)을 공통으로 사용하는 $2 \times 2$ 표의 오즈비. 이 역시 $(I-1)(J-1)$개가 있다.
*   **결론**: $I \times J$ 표의 연관성은 $(I-1)(J-1)$개의 오즈비로 완벽하게 설명될 수 있다. 모든 오즈비가 1이면 두 변수는 독립이다.

#### **2.4.2: 각 셀별로 독립성과의 편차 보기**

*   **아이디어**: 전체적인 연관성 대신, 각 개별 셀($ij$)이 독립성 가정 하에서 기대되는 것보다 얼마나 더/덜 흔하게 나타나는지 본다.
*   **연관성 요인**:

$$ \frac{\pi_{ij}}{\pi_{i+}\pi_{+j}} = \frac{\text{실제 셀 확률}}{\text{독립성 하에서의 기대 확률}} $$

*   **해석**:
    *   **값이 1**: 해당 셀은 독립성 가정과 정확히 일치한다.
    *   **값이 1보다 큼 (예: 2)**: 독립일 때보다 2배 더 흔하게 발생했다. 양의 연관성을 시사.
    *   **값이 1보다 작음 (예: 0.5)**: 독립일 때보다 절반밖에 발생하지 않았다. 음의 연관성을 시사.
*   **용도**: 잔차 분석과 유사하게, 어느 셀이 전체적인 연관성에 크게 기여하는지 식별하는 데 유용하다.

#### **2.4.3: 연관성을 단 하나의 숫자로 요약하기 (PRE 측도)**

*   **아이디어**: "설명 변수 X를 알게 되었을 때, 반응 변수 Y의 불확실성(변동)이 얼마나 줄어들었는가?"를 측정한다. 이를 **오차의 비례적 감소(Proportional Reduction in Error, PRE)** 측도라고 한다.
*   **구조**:

$$ \text{PRE 측도} = \frac{V(Y) - E[V(Y|X)]}{V(Y)} $$

*   $V(Y)$: X를 모르고 Y만 볼 때의 총 변동 (예: 엔트로피).
*   $E[V(Y|X)]$: X의 각 수준별로 Y의 변동을 계산한 후, 이를 평균낸 '조건부 변동'.

*   **해석**:
    *   **값이 0**: X를 알아도 Y의 불확실성이 전혀 줄지 않았다. $\implies$ **독립**.
    *   **값이 1**: X를 알면 Y의 결과가 완벽하게 예측된다. $\implies$ **완전한 종속**.
    *   **값이 0.3**: X를 알게 됨으로써 Y의 불확실성(예측 오차)이 30% 감소했다.
*   **불확실성 계수 ($U$)**: 변동성의 척도로 정보이론의 **엔트로피**를 사용한 PRE 측도. 명목형 변수에 사용된다.
*   **한계**: "엔트로피 30% 감소"가 실제적으로 얼마나 강한 연관성인지 직관적으로 이해하기 어렵다. 이러한 이유로, 순서형 변수에 대한 요약 측도가 더 널리 사용된다.

**종합 요약**: $I \times J$ 표의 연관성을 기술하는 방법은 하나가 아니다.
1.  **오즈비 집합**: 연관성의 전체 구조를 상세하게 분해하여 보여준다.
2.  **연관성 요인**: 각 셀 단위로 독립성과의 편차를 보여준다.
3.  **요약 측도 (PRE)**: 연관성의 전체적인 강도를 0과 1 사이의 단일 숫자로 요약하여 제공한다.
분석의 목적에 따라 이러한 방법들을 적절히 조합하여 사용하는 것이 중요하다.
