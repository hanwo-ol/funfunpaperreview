### 6.2.4 로지스틱 회귀의 영향력 진단 (Influence Diagnostics for Logistic Regression)

[원문 번역]

다른 회귀 진단 도구들 또한 적합도를 평가하는 데 도움이 된다. 여기에는 순서화된 표준화 잔차를 정규 백분위수와 비교하는 플롯(Haberman 1973a)과, 모수 추정치 및 적합도 통계량에 대한 한 관측치의 영향을 기술하는 분석들이 포함된다. 잔차가 어떤 모델이 한 관측치에 형편없이 맞는다는 것을 나타낼 때마다, 그 관측치를 삭제하고 나머지 데이터로 모델을 다시 적합시켜 보는 것이 유익할 수 있다. 이것은 그 관측치에 대해 완벽한 적합을 강제하는, 그 관측치에 대한 모수를 모델에 추가하는 것과 동등하다.

비그룹화된 이항 데이터에 대해, 이상치(outlier)의 개념은 보통의 회귀분석에서처럼 명확하지 않다. Copas(1988)는 확률적인 정의를 사용했는데, 이에 따르면 만약 적합된 모델이 사실이라면 그 관측치가 발생할 가능성이 매우 낮을 경우를 말한다. 그러나, 만약 설명 변수 값들의 특정 영역에 걸쳐 $\hat{\pi} _i$가 1에 가깝거나 0에 가깝다면, 일부 이상치를 관찰하는 것은 전혀 놀랍지 않다. Copas는 다양한 모델들이 이상치에 대한 민감도에서 어떻게 다른지를 연구했다.

보통의 회귀분석에서처럼, 단일 관측치가 모수 추정치를 결정하는 데 꽤 영향력이 클 수 있다. 관측치의 레버리지(leverage)가 클수록, 그것의 잠재적 영향력은 더 크다. 만약 $y$에서 이상치로 보이고 큰 레버리지를 갖는 관측치가 삭제된다면 적합 결과는 상당히 달라질 수 있다. 하지만, 보통의 최소제곱 회귀분 " ”서는 $y _i$가 그것의 기댓값으로부터의 거리에 제한이 없기 때문에, 단일 관측치가 로지스틱 회귀에서보다 훨씬 더 엄청난 영향을 가질 수 있다. 4.5.6절에서 우리는 GLM의 추정된 햇 행렬

$$ \mathbf{H} _{at} = \mathbf{W}^{1/2}\mathbf{X}(\mathbf{X}^T\mathbf{W}\mathbf{X})^{-1}\mathbf{X}^T\mathbf{W}^{1/2} $$

이 모델 행렬 $\mathbf{X}$뿐만 아니라 적합 결과에도 의존함을 보았다. 로지스틱 회귀에 대해, (5.5.2절로부터) 가중치 행렬 $\mathbf{W}$는 원소 $w _i = n _i\hat{\pi} _i(1-\hat{\pi} _i)$를 갖는 대각 행렬임을 상기하라. 극단적인 예측 변수 값을 갖는 점들이 반드시 높은 레버리지를 갖지는 않는다. 사실, 만약 $\hat{\pi} _i$가 0 또는 1에 가깝다면 레버리지는 비교적 작을 수 있다.

몇몇 측도들은 데이터셋에서 한 관측치를 제거하는 효과를 기술한다. 그것들은 관측치의 레버리지와 대수적으로 관련되어 있다 (Pregibon 1981, Williams 1987). 로지스틱 회귀에서, 관측치는 단일 이항 반응이거나 또는 모두 동일한 예측 변수 값을 갖는 피험자 집합에 대한 이항 반응일 수 있다 (즉, 비그룹화 또는 그룹화 데이터). 각 관측치에 대해, 그 관측치를 삭제하는 영향력 측도들은 다음을 포함한다:

1.  각 모델 모수에 대해, 그것의 추정치의 변화. 이 변화를 그것의 표준오차로 나눈 것을 Dfbeta라고 부른다.
2.  모수들에 대한 결합 신뢰구간의 변화에 대한 측도. 이 신뢰구간 이동 진단(confidence interval displacement diagnostic)은 $c$로 표기된다.
3.  $X^2$ 또는 $G^2$ 적합도 통계량의 변화. Pregibon(1982)은 $X^2$의 변화가 해당 관측치에 대한 표준화 잔차의 제곱을 근사함을 보였다.

각 측도에 대해, 값이 클수록 영향력은 더 크다. 연속형 또는 다중 예측 변수가 있을 때, 예를 들어 추정된 확률에 대해 이러한 진단 값들을 플로팅하는 것이 유익할 수 있다.

---

### 핵심 내용 해설: 어떤 데이터 포인트가 모델을 좌우하는가?

잔차 분석이 "모델이 어떤 데이터 포인트에 잘 맞지 않는가?"를 알려준다면, 영향력 진단(Influence Diagnostics)은 "어떤 데이터 포인트가 모델 자체를 뒤흔드는가?"라는 더 근본적인 질문에 답합니다.

#### 이상치(Outlier) vs. 영향점(Influential Point)

*   이상치(Outlier): 모델의 예측에서 멀리 벗어난 관측치. (Y-방향의 특이점). 큰 잔차를 갖습니다.
*   높은 레버리지 점(High Leverage Point): 설명 변수(X)의 값이 다른 데이터 포인트들의 패턴에서 멀리 벗어난 관측치. (X-방향의 특이점).
*   영향점(Influential Point): 이 관측치를 데이터셋에서 제거했을 때, 모델의 적합 결과(특히 회귀 계수 $\hat{\beta}$)가 크게 변하는 관측치.
    *   중요: 모든 이상치나 모든 레버리지 점이 영향점인 것은 아닙니다. 보통 이상치이면서 동시에 높은 레버리지를 갖는 점이 가장 강력한 영향점이 되는 경향이 있습니다.

#### 로지스틱 회귀에서의 특수성

*   이상치의 개념이 모호함: 반응 변수 $Y$가 0 또는 1밖에 없으므로, OLS처럼 잔차가 극단적으로 커질 수 없습니다.
*   레버리지의 의존성: OLS에서 레버리지는 오직 X값에만 의존하지만, GLM에서는 적합치($\hat{\pi} _i$)에도 의존합니다. $\hat{\pi} _i$가 0 또는 1에 가까워지면, 해당 관측치의 가중치($w _i$)가 0에 가까워져 레버리지가 작아질 수 있습니다. 이는 X값이 극단적이더라도 영향력이 크지 않을 수 있음을 의미합니다.

#### 주요 영향력 진단 측도 (Leave-One-Out 방식)

이 측도들은 모두 "만약 $i$번째 관측치가 없었다면, 결과가 얼마나 달라졌을까?"라는 '가상 실험'에 기반합니다.

1.  Dfbeta ($D\hat{\beta}$):
    *   계산: ($i$번째 관측치를 뺀 모델의 $\hat{\beta}$) - (전체 데이터 모델의 $\hat{\beta}$) 를 $\hat{\beta}$의 표준오차로 나눈 값.
    *   해석: "$i$번째 관측치를 제거했을 때, 특정 회귀 계수 $\hat{\beta} _j$가 표준오차의 몇 배만큼 변하는가?"
    *   특정 계수에 대한 영향력을 개별적으로 평가합니다.

2.  신뢰구간 이동 ($c$):
    *   계산: Dfbeta와 유사하지만, 개별 계수가 아닌 모든 계수($\boldsymbol{\beta}$)에 대한 결합 신뢰 영역(타원)이 얼마나 이동하는지를 측정합니다.
    *   해석: "$i$번째 관측치를 제거했을 때, 모델 전체의 모수 추정치가 얼마나 불안정해지는가?"

3.  적합도 통계량의 변화 ($\Delta X^2, \Delta G^2$):
    *   계산: ($i$번째 관측치를 뺀 모델의 $X^2$) - (전체 데이터 모델의 $X^2$)
    *   해석: "$i$번째 관측치를 제거했을 때, 모델의 전반적인 적합도가 얼마나 변하는가?"
    *   Pregibon의 발견: $\Delta X^2 \approx r _i^2$ (표준화 잔차의 제곱). 이는 큰 잔차를 갖는 관측치가 적합도에 큰 영향을 미친다는 직관과 일치합니다.

#### 실용적인 사용법

*   이러한 진단 측도들을 모든 관측치에 대해 계산합니다.
*   다른 값들에 비해 유난히 큰 값을 갖는 관측치를 영향점으로 의심합니다.
*   영향점 플롯(influence plot)을 그려서 어떤 관측치가 문제인지 시각적으로 확인합니다.
*   조치:
    *   영향점이 데이터 입력 오류나 측정 오류인지 확인합니다.
    *   오류가 아니라면, 왜 그 관측치가 다른 패턴을 보이는지 이론적으로 고찰합니다.
    *   분석의 민감도를 보여주기 위해, 해당 영향점을 포함한 결과와 제외한 결과를 모두 보고할 수 있습니다.
    *   단순히 마음에 들지 않는다는 이유로 영향점을 무조건 삭제해서는 안 됩니다. 그 점은 데이터의 중요한 특징을 담고 있을 수 있습니다.

결론: 잔차 분석이 모델의 '평균적인' 적합성을 본다면, 영향력 진단은 '개별적인' 데이터 포인트가 모델 구축 과정에 미치는 과도한 영향력을 탐지하는 데 필수적입니다. 신뢰성 있는 모델을 구축하기 위해서는, 모델이 소수의 특정 관측치에 의해 좌우되지 않는다는 것을 확인하는 과정이 반드시 필요합니다.
