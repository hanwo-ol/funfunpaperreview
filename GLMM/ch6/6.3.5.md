### 6.3.5 예제: 투구게 데이터의 예측력 평가 (Example: Evaluating Predictive Power for Horseshoe Crab Data)

[원문 번역]

표 6.2는 암컷 게가 적어도 하나의 위성을 가졌는지 여부를 예측하기 위해 투구게 데이터에 적합된 몇몇 모델들에 대한 상관계수 $R(\mathbf{y}, \hat{\boldsymbol{\mu}})$를 보여준다. 색깔 단독(C)으로는 $R=0.285$, 너비 단독(W)으로는 $R=0.402$이며, 둘 다 사용하면(C+W) $R$이 0.452로 증가한다. 게가 어두운지 여부만을 나타내기 위해 색깔을 이항 변수로 사용하는 더 단순한 모델(C=dark+W)은 $R=0.447$로 거의 비슷한 성능을 보인다. 이 모델들은 표에 보이지 않는 더 복잡한 모델들만큼 본질적으로 잘 맞는다. 예를 들어, (C=dark+W) 모델에 상호작용 항을 추가한 모델은 $R=0.452$를 갖는다.

다른 예측력 측도들은 다른 크기를 갖지만, 다양한 모델들을 비교하는 데 있어서는 유사한 결과를 낳는다. 예를 들어, 일치 지수 $c$는 (요인 형태의) 모델 (C)에 대해 0.639, 모델 (W)에 대해 0.742, 모델 (C+W)에 대해 0.771, 모델 (C=dark+W)에 대해 0.772, 그리고 이 모델에 상호작용 항을 추가한 모델에 대해 0.772이다.

다음으로, 우리는 모델 (C+W)에 대한 분류표를 설명한다. 173마리의 게 중에서, 111마리가 위성을 가지고 있었으므로, 표본 비율은 0.642이다. 표 6.8은 교차 검증된 예측을 사용하여 $\pi_0=0.50$과 $\pi_0=0.642$를 사용한 분류표를 보여준다. $\pi_0=0.642$일 때, 표 6.8로부터 추정된 민감도는 $74/111=0.667$이고 특이도는 $42/62=0.677$이다. 정분류 비율은 $(74+42)/173 = 0.671$이다.

그림 6.4는 SAS의 PROC LOGISTIC이 모델 (C+W)에 대한 ROC 곡선을 어떻게 보고하는지 보여준다. $\pi_0=0.642$일 때, 특이도=0.68, 민감도=0.67이며, 플로팅된 점은 좌표 (0.32, 0.67)을 갖는다. 곡선 아래 면적은 $c=0.771$이다.

---

### 핵심 내용 해설: 어떤 모델이 가장 예측을 잘하는가?

이 예제는 하나의 데이터셋(투구게)에 여러 다른 로지스틱 회귀 모델을 적합시킨 후, 6.3절에서 배운 예측력 지표들을 사용하여 "어떤 모델이 가장 예측을 잘하는가?"라는 질문에 답하는 과정을 보여줍니다.

#### 비교 대상 모델들

*   C: 색깔만 예측 변수로 사용 (명목형 취급)
*   W: 너비만 예측 변수로 사용 (양적 변수)
*   C+W: 색깔과 너비의 주효과만 사용 (상호작용 없음)
*   C=dark+W: 색깔을 '어두움 vs. 나머지'의 이항 변수로 단순화하여 너비와 함께 사용
*   C=dark\*W: 이분화된 색깔과 너비, 그리고 둘의 상호작용 항까지 포함

#### 1. R과 일치 지수(AUC)를 이용한 모델 비교

| 모델 | R($\mathbf{y}, \hat{\boldsymbol{\mu}}$) (상관계수) | c (일치 지수, AUC) | 해석 |
| :--- | :--- | :--- | :--- |
| C (색깔) | 0.285 | 0.639 | 색깔만으로는 예측력이 그리 좋지 않다. |
| W (너비) | 0.402 | 0.742 | 너비만 사용해도 색깔보다 훨씬 예측력이 좋다. |
| C+W | 0.452 | 0.771 | 색깔과 너비를 함께 사용하면 예측력이 더 향상된다. |
| C=dark+W | 0.447 | 0.772 | 색깔을 단순화해도 예측력은 거의 떨어지지 않는다. |
| C=dark\*W | 0.452 | 0.772 | 상호작용 항을 추가해도 예측력은 거의 향상되지 않는다. |

분석 결과:
*   너비(W)가 색깔(C)보다 훨씬 더 중요한 예측 변수임을 알 수 있습니다.
*   너비와 색깔을 함께 사용하면(C+W) 예측력이 가장 좋아집니다.
*   복잡한 4범주 색깔 변수를 '어두움 vs. 나머지'라는 단순한 이항 변수로 만들어도(C=dark+W) 성능이 거의 유지됩니다. 이는 모델을 더 간결하게 만들 수 있다는 중요한 단서입니다.
*   상호작용 항을 추가하는 것은 예측력 향상에 거의 기여하지 않습니다. 따라서 상호작용은 불필요해 보입니다.

결론: 예측력과 간결성(parsimony)을 모두 고려할 때, (C=dark+W) 모델 또는 (C+W) 모델이 가장 합리적인 선택으로 보입니다.

#### 2. 분류표를 이용한 예측력 평가 (모델 C+W 예시)

*   컷오프($\pi_0$) 설정:
    *   $\pi_0=0.50$: 가장 일반적인 기준. "확률이 50%를 넘으면 1로 예측"
    *   $\pi_0=0.642$ (표본 평균): 전체 데이터의 '성공'(위성 있음) 비율을 기준으로 사용.
*   결과 (표 6.8, $\pi_0=0.642$ 기준):
    *   민감도: $74/111 = 66.7\%$. (실제로 위성이 있는 게들 중 66.7%를 '있음'으로 올바르게 예측)
    *   특이도: $42/62 = 67.7\%$. (실제로 위성이 없는 게들 중 67.7%를 '없음'으로 올바르게 예측)
    *   정확도: $(74+42)/173 = 67.1\%$. (전체 게들 중 67.1%의 상태를 올바르게 예측)
*   해석: 이 모델은 대략 2/3 정도의 예측 정확도를 보입니다. 완벽하지는 않지만, 무작위 추측(50%)보다는 훨씬 나은 성능입니다.

#### 3. ROC 곡선을 이용한 예측력 평가 (모델 C+W 예시)

*   AUC 값: 0.771.
*   해석:
    *   일치 지수(c-statistic)의 값과 동일합니다.
    *   "실제로 위성이 있는 게 한 마리와 없는 게 한 마리를 무작위로 뽑았을 때, 우리 모델이 위성 있는 게에게 더 높은 확률을 부여할 확률이 77.1%"라는 의미입니다.
    *   일반적으로 AUC가 0.7~0.8 사이이면 "수용 가능한(acceptable)" 판별력을, 0.8 이상이면 "우수한(excellent)" 판별력을 갖는다고 평가합니다. 따라서 이 모델의 예측력은 꽤 괜찮은 수준이라고 할 수 있습니다.
*   그림 6.4의 점: 그림의 ROC 곡선 위에 찍힌 점은 컷오프 $\pi_0=0.642$일 때의 성능을 나타냅니다.
    *   x좌표 = $1 - \text{특이도} = 1 - 0.68 = 0.32$
    *   y좌표 = 민감도 = 0.67
    *   이 점은 ROC 곡선이 제공하는 수많은 가능한 성능 조합 중 하나일 뿐입니다.

종합 요약: 이 예제는 R, AUC, 분류표 등 다양한 예측력 지표들이 어떻게 서로 다른 정보를 제공하면서도 모델 비교에 있어서는 일관된 결론(예: 'W가 C보다 낫다', 'C+W가 W보다 낫다')을 도출하는지를 보여줍니다. 어떤 단일 지표만 보기보다는, 여러 지표를 종합적으로 사용하여 모델의 성능을 다각도로 평가하는 것이 중요합니다.
