### 6.3.3 예측력 요약: 분류표 (Summarizing Predictive Power: Classification Tables)

[원문 번역]

분류표(classification table)는 이항 반응을 $y=0$ 또는 1의 예측과 교차 분류한다. 관측치 $i$에 대한 예측은 어떤 컷오프(cutoff) $\pi _0$에 대해 $\hat{\pi} _i > \pi _0$일 때 $\hat{y} _i=1$이고 $\hat{\pi} _i \le \pi _0$일 때 $\hat{y} _i=0$이다. 한 가지 가능성은 $\pi _0=0.50$이다. 다른 하나는 1인 결과들의 표본 비율이며, 이는 절편 항만 포함하는 모델에 대한 $\hat{\pi} _i$이다. $y _i$가 하나의 원소였던 데이터셋에 적합된 모델로부터 나온 $\hat{\pi} _i$를 사용하는 것보다, $\hat{\pi} _i$가 다른 $n-1$개의 관측치에 적합된 모델에 기반하는 "하나 빼기(leave-one-out)" 교차 검증 접근법으로 예측을 하는 것이 더 낫다.

분류표를 사용하여, 우리는 다음과 같이 예측력을 요약할 수 있다.

$$ \text{민감도} = P(\hat{y}=1 | y=1) \quad \text{그리고} \quad \text{특이도} = P(\hat{y}=0 | y=0) $$

(2.1.3절 상기). 예측력의 전반적인 요약은 정분류 비율이다. 이것은 다음을 추정한다.

$$ P(\text{정분류}) = P(y=1, \hat{y}=1) + P(y=0, \hat{y}=0) $$

$$ = P(\hat{y}=1|y=1)P(y=1) + P(\hat{y}=0|y=0)P(y=0) $$

이것은 민감도와 특이도의 가중 평균이다.

분류표는 한계를 갖는다: 그것은 연속적인 예측값 $\hat{\pi} _i$를 이진 값으로 붕괴시킨다. $\pi _0$의 선택은 임의적이다. 결과는 $y=1$인 경우와 $y=0$인 경우의 상대적인 수에 민감하다. 예를 들어, 만약 $y=1$인 관측치의 비율이 낮다면, 모델 적합은 결코 $\hat{\pi} _i > 0.50$을 갖지 않을 수 있으며, 그 경우 우리는 결코 $\hat{y}=1$을 예측하지 않는다. 다시 말해, 주된 용도는 동일한 데이터에 대한 다른 모델들을 비교하기 위함이다.

### 6.3.4 예측력 요약: ROC 곡선 (Summarizing Predictive Power: ROC Curves)

[원문 번역]

분류표 요약은 분류를 만들기 위한 컷오프 $\pi _0$에 의존한다. 수신자 조작 특성(Receiver Operating Characteristic, ROC) 곡선은 가능한 모든 $\pi _0$에 대해 민감도를 (1-특이도)의 함수로 플로팅한 것이다. ROC 곡선은 모든 가능한 $\pi _0$에 대한 예측력을 요약하기 때문에 분류표보다 더 유익한 정보를 제공한다. $\pi _0$가 0에 가까울 때, 거의 모든 예측은 $\hat{y}=1$이다; 그러면, 민감도는 1에 가깝고, 특이도는 0에 가까우며, (1-특이도, 민감도) 점은 $\approx (1,1)$이다. $\pi _0$가 1에 가까울 때, 거의 모든 예측은 $\hat{y}=0$이다; 그러면, 민감도는 0에 가깝고, 특이도는 1에 가까우며, (1-특이도, 민감도) 점은 $\approx (0,0)$이다. ROC 곡선은 보통 (0,0)과 (1,1)을 잇는 오목한(concave) 모양을 갖는다.

주어진 특이도에 대해, 더 나은 예측력은 더 높은 민감도에 해당한다. 따라서, 예측력이 좋을수록, ROC 곡선은 더 높다. 요약적인 의미에서, ROC 곡선 아래 면적(area under the ROC curve, AUC)이 클수록, 예측은 더 좋다. 사실, ROC 곡선 아래 면적은 예측력의 또 다른 측도, 즉 일치 지수(concordance index)의 값과 동일하다 (Hanley and McNeil 1982). $y _i=1$이고 $y _j=0$인 모든 관측치 쌍 $(i,j)$를 고려해보자. 일치 지수 $c$는 $\hat{\pi} _i > \hat{\pi} _j$인 그러한 쌍들의 비율이다; 즉, 그것은 쌍을 이루는 예측과 결과가 일치하는 상대 빈도이며, 더 큰 $y$를 갖는 관측치가 더 큰 $\hat{\pi}$를 갖는다. $c=0.50$인 값은 예측이 무작위 추측보다 나을 것이 없음을 의미한다. 이것은 절편 항만 갖는 모델과 (0,0)과 (1,1)을 잇는 직선인 ROC 곡선에 해당한다.

---

### 핵심 내용 해설: 예측 성능을 평가하는 실용적인 도구

이 섹션들은 모델의 예측 성능을 평가하고 비교하는 데 가장 널리 사용되는 두 가지 방법인 분류표와 ROC 곡선을 소개합니다. 이는 모델이 통계적으로 유의한지를 넘어, "실제로 얼마나 잘 맞추는가?" 라는 실용적인 질문에 답합니다.

#### 6.3.3: 간단하지만 함정이 있는 분류표

*   아이디어: 로지스틱 회귀는 0과 1 사이의 '확률'($\hat{\pi} _i$)을 예측합니다. 이를 실제 의사결정에 사용하려면, "이 확률이 특정 기준(컷오프, $\pi _0$)보다 높으면 '성공(1)'으로 예측하고, 낮으면 '실패(0)'로 예측하자"는 규칙을 만듭니다.
*   분류표 (Confusion Matrix): 이 규칙에 따른 예측($\hat{y}$)과 실제 결과($y$)를 $2 \times 2$ 표로 비교한 것입니다.

| | 예측: 1 | 예측: 0 |
| :--- | :--- | :--- |
| 실제: 1 | True Positive(TP) | False Negative(FN) |
| 실제: 0 | False Positive(FP) | True Negative(TN) |

*   주요 성능 지표:
    *   민감도 (Sensitivity, Recall): $\frac{TP}{TP+FN} = P(\hat{y}=1 | y=1)$. 실제 1인 것들 중 얼마나 많이 1로 맞췄는가? (환자를 놓치지 않는 능력)
    *   특이도 (Specificity): $\frac{TN}{TN+FP} = P(\hat{y}=0 | y=0)$. 실제 0인 것들 중 얼마나 많이 0으로 맞췄는가? (정상인을 환자로 오진하지 않는 능력)
    *   정확도 (Accuracy): $\frac{TP+TN}{\text{Total}} = P(\text{정분류})$. 전체 중 얼마나 맞췄는가.

*   한계점:
    1.  컷오프($\pi _0$)의 자의성: 가장 큰 문제입니다. 컷오프를 0.5로 할지, 0.6으로 할지에 따라 민감도와 특이도가 크게 변합니다. 어떤 컷오프가 최적인지에 대한 명확한 답이 없습니다.
    2.  정보 손실: 0.01~1.0 사이의 풍부한 확률 정보를 단지 0/1 예측으로 붕괴시켜 많은 정보를 잃게 됩니다.
    3.  불균형 데이터 문제: 실제 1의 비율이 매우 낮은 경우(예: 희귀 질병), 모델이 예측하는 모든 확률 $\hat{\pi} _i$가 0.5보다 작을 수 있습니다. 그러면 컷오프 0.5를 사용하면 모든 사람을 0으로 예측하게 되어, 민감도는 0이 되는 비상식적인 결과가 나옵니다.

#### 6.3.4: 컷오프 문제를 해결한 ROC 곡선

*   아이디어: "하나의 컷오프에 의존하지 말고, 모든 가능한 컷오프에 대해 모델의 성능이 어떻게 변하는지를 한 번에 보여주자."
*   ROC 곡선 (Receiver Operating Characteristic Curve):
    *   x축: 1 - 특이도 (False Positive Rate, 위양성률)
    *   y축: 민감도 (True Positive Rate, 진양성률)
    *   생성 과정: 컷오프 $\pi _0$를 1에서 0으로 점차 낮추면서, 각 컷오프 지점에서의 (1-특이도, 민감도) 쌍을 좌표 평면에 점으로 찍고 그 점들을 연결합니다.
*   ROC 곡선 해석:
    *   곡선은 항상 (0,0)에서 시작하여 (1,1)에서 끝납니다.
    *   완벽한 모델: 곡선이 왼쪽 상단 모서리 (0,1)에 붙습니다. (특이도 1, 민감도 1을 동시에 달성)
    *   무작위 추측 모델: 곡선이 대각선($y=x$)을 따릅니다.
    *   좋은 모델: 곡선이 대각선보다 왼쪽 위로 많이 휘어질수록 더 좋은 모델입니다. 이는 같은 위양성률(1-특이도)에서 더 높은 민감도를 달성한다는 의미입니다.

*   곡선 아래 면적 (Area Under the Curve, AUC):
    *   ROC 곡선이라는 '그림'을 단 하나의 숫자로 요약한 것입니다.
    *   값의 범위: 0.5 ~ 1.0
    *   해석:
        *   AUC = 1.0: 완벽한 분류 모델
        *   AUC = 0.5: 무작위 추측과 다를 바 없는 모델
        *   AUC > 0.8: 보통 우수한 모델로 간주
        *   확률적 해석 (일치 지수, c-statistic): "실제 1인 사람과 실제 0인 사람을 한 명씩 무작위로 뽑았을 때, 모델이 실제 1인 사람에게 더 높은 확률을 부여할 확률"과 같습니다. 이것이 AUC의 가장 직관적인 해석입니다.

결론: 분류표는 특정 컷오프에서의 성능을 보여주는 간단한 도구이지만, 그 자의성 때문에 한계가 명확합니다. 반면, ROC 곡선과 AUC는 모든 가능한 컷오프에 대한 모델의 전반적인 판별 능력을 종합적으로 평가해주므로, 모델의 예측력을 비교하고 평가하는 데 훨씬 더 우수하고 표준적인 방법입니다.
