### 6.1.3 단계적 절차: 전진 선택법과 후진 제거법 (Stepwise Procedures: Forward Selection and Backward Elimination)

[원문 번역]

탐색적 연구에서, 결과들을 신중하게 사용한다면 모델들을 탐색하는 알고리즘적인 방법이 유익한 정보를 줄 수 있다. Goodman(1971a)은 보통의 회귀분석에서의 전진 선택법과 후진 제거법에 유사한 방법들을 제안했다.

전진 선택법(Forward selection)은 순차적으로 항들을 추가한다. 각 단계에서, 그것은 적합도에서 가장 큰 개선을 가져오는 항을 선택한다. 모델에 있는 항에 대한 검정의 최소 P-값은 합리적인 기준인데, 왜냐하면 다른 항들에 대한 이탈도의 감소량이 다른 자유도 값을 가질 수 있기 때문이다. 예측 변수들을 추가하다 보면, 새로운 예측 변수들이 이미 사용된 것들과 너무 상관관계가 높아 예측력을 향상시키지 못하는, 수확 체감의 지점이 발생한다. 추가적인 추가가 적합도를 유의하게 향상시키지 못할 때 과정은 멈춘다. 이 절차의 단계적(stepwise) 변형은 각 단계에서, 이전에 추가된 항들이 여전히 유의한지를 재검정한다.

후진 제거법(Backward elimination)은 복잡한 모델에서 시작하여 순차적으로 항들을 제거한다. 각 단계에서, 그것은 모델에 가장 적은 손상을 주는 (예: 가장 큰 P-값을 갖는) 항을 선택한다. 어떤 추가적인 삭제가 유의하게 더 나쁜 적합을 초래할 때 과정은 멈춘다. 어느 접근법에서든, 두 개 이상의 범주를 갖는 질적 예측 변수에 대해, 그 과정은 개별 지시 변수만이 아닌 어떤 단계에서든 전체 변수를 고려해야 한다. 그것의 지시 변수 중 하나만이 아닌 전체 변수를 추가하거나 제거해야 한다. 그렇지 않으면, 결과는 지시 변수 코딩의 기준선 선택에 의존하게 된다. 동일한 언급이 그 변수를 포함하는 상호작용에도 적용된다.

일부 통계학자들은 전진 선택법보다 후진 제거법을 선호하는데, 지나치게 단순한 모델에 항을 추가하는 것보다 지나치게 복잡한 모델에서 항을 삭제하는 것이 더 안전하다고 느끼기 때문이다. 전진 선택법은 그 순서의 특정 검정이 검정력이 낮기 때문에 조기에 멈출 수 있다. 어느 전략도 반드시 의미 있는 모델을 산출하지는 않는다. 변수 선택 절차는 신중하게 사용하라! 다양한 연구들이 그 한계와 함정을 보여주었다 (예: Steyerberg et al. 2001). 많은 항들을 평가할 때, 실제로는 중요하지 않은 한두 개가 단지 우연 때문에 인상적으로 보일 수 있다. 예를 들어, 모든 실제 효과가 약할 때, 가장 큰 표본 효과는 그것의 실제 효과를 상당히 과대평가할 가능성이 높다. 그러한 알고리즘은 비공식적인 방식으로 사용하는 것이 최선이다. 이것은 컷오프 포인트로 사용되는 P-값의 해석을 포함하는데, 왜냐하면 예측 변수 집합에 걸쳐 평가된 최소 또는 최대 P-값의 분포는 미리 선택된 변수에 대한 P-값의 분포와 같지 않기 때문이다.

일부 소프트웨어는 모델 선택을 위한 추가적인 옵션들을 가지고 있다. 한 접근법은 어떤 기준에 따라, 고정된 수의 항을 가진 최상의 모델을 결정하려고 시도한다. 만약 그러한 방법과 전후진 선택 절차들이 상당히 다른 모델들을 산출한다면, 이는 그러한 결과들이 의심스러운 사용 가치를 갖는다는 지표이다. 또 다른 그러한 지표는, 표본 분포로부터 동일한 크기의 부트스트랩(bootstrap) 표본에 주어진 절차를 적용했을 때 상당히 다른 모델이 나올 경우이다.

마지막으로, 통계적 유의성이 모델에 항을 포함하는 유일한 기준이 되어서는 안 되며, 어떤 경우든 실제 유의성을 판단하기는 어려울 수 있다 (Westfall and Young 1993). 연구의 목적에 중심적인 변수는 통계적으로 유의하지 않더라도 포함시키고 그 추정된 효과를 보고하는 것이 합리적이다. 그것을 모델에 유지하는 것은 다른 예측 변수들의 추정된 효과에 대한 편향을 줄이는 데 도움이 될 수 있고, 아마도 더 큰 표본 크기 때문에 효과가 유의했던 다른 연구들과 결과를 비교하는 것을 가능하게 할 수 있다. 알고리즘적인 선택 절차는 모델의 구성을 안내하는 신중한 사고를 대체할 수 없다.

---

### 핵심 내용 해설: 최적의 모델을 찾는 자동화된 탐색기

수많은 예측 변수 후보가 있을 때, 어떤 변수 조합이 최상의 모델을 만드는지 일일이 확인하는 것은 불가능합니다. 단계적 절차는 이 탐색 과정을 자동화하는 알고리즘입니다.

#### 1. 전진 선택법 (Forward Selection)

*   철학: "가장 단순한 모델에서 시작하여, 가장 중요한 변수부터 하나씩 차례로 추가해 나가자."
*   과정:
    1.  시작: 절편만 있는 모델(아무 변수도 없는 모델)에서 시작한다.
    2.  첫 번째 변수 선택: 모델에 추가했을 때 적합도를 가장 많이 향상시키는 (예: 우도비 검정의 P-값이 가장 작은) 변수 하나를 찾는다.
    3.  선택 및 반복: 그 변수를 모델에 추가하고, 2번 과정을 반복하여 남은 변수들 중에서 가장 중요한 다음 변수를 찾는다.
    4.  종료: 더 이상 모델에 추가해도 적합도가 "유의미하게" 향상되지 않는 변수가 없을 때 (예: 모든 후보 변수의 P-값이 특정 기준보다 클 때) 과정을 멈춘다.
*   장점: 계산이 빠르다. 변수가 매우 많을 때 유용하다.
*   단점: 초기에 잘못된 변수가 선택되면 그 결정이 끝까지 영향을 미칠 수 있다. 두 변수가 함께 들어왔을 때만 강력한 효과를 내는 경우를 놓칠 수 있다.

#### 2. 후진 제거법 (Backward Elimination)

*   철학: "가장 복잡한 모델에서 시작하여, 가장 쓸모없는 변수부터 하나씩 차례로 제거해 나가자."
*   과정:
    1.  시작: 모든 예측 변수를 포함한 전체 모델(full model)에서 시작한다.
    2.  첫 번째 변수 제거: 모델에서 제거했을 때 적합도에 손상을 가장 적게 주는 (예: P-값이 가장 큰, 즉 가장 유의하지 않은) 변수 하나를 찾는다.
    3.  제거 및 반복: 그 변수를 모델에서 제거하고, 2번 과정을 반복하여 남은 변수들 중에서 가장 덜 중요한 다음 변수를 찾는다.
    4.  종료: 모델에 남아있는 모든 변수들이 "유의미할" 때 (예: 모든 변수의 P-값이 특정 기준보다 작을 때) 과정을 멈춘다.
*   장점: 변수들 간의 복잡한 상호작용을 고려한 상태에서 시작하므로 전진 선택법보다 더 안정적인 모델을 찾는 경향이 있다. 많은 통계학자들이 더 선호한다.
*   단점: 변수가 매우 많으면 전체 모델을 적합시키는 것 자체가 불가능할 수 있다.

#### 3. 단계적 선택법 (Stepwise Selection)

*   철학: 전진 선택법과 후진 제거법을 결합.
*   과정: 전진 선택법처럼 변수를 추가하되, 각 단계마다 이미 모델에 포함된 변수들 중에 더 이상 유의하지 않게 된 변수가 있는지 검사하여 제거한다.
*   장점: 초기의 잘못된 결정을 수정할 기회를 제공한다.
*   단점: 더 복잡하고, 결과가 안정적이지 않을 수 있다.

#### 매우 중요한 주의사항: "맹신은 금물!"

본문은 이러한 자동화된 절차를 사용할 때의 위험성을 강력하게 경고합니다.

1.  "최상의" 모델은 없다: 이 알고리즘들은 단지 특정 기준에 따라 "좋은" 모델 후보를 제시할 뿐, 그것이 유일하거나 진정한 "정답" 모델임을 보장하지 않는다.
2.  우연의 효과(Chance Effects): 수많은 변수를 테스트하다 보면, 실제로는 아무 효과가 없는 변수라도 순전히 우연에 의해 P-값이 작게 나와 모델에 선택될 수 있다 (다중 비교 문제).
3.  P-값의 오용: 이 과정에서 사용되는 P-값은 "가장 좋거나 나쁜" 것을 선택하기 위한 기준으로 사용된 것이므로, 일반적인 가설 검정의 P-값과 동일하게 해석해서는 안 된다.
4.  이론적 배경 무시: 알고리즘은 변수의 실제적인 중요성이나 이론적 배경을 전혀 고려하지 않는다. 연구의 핵심적인 변수가 통계적으로 유의하지 않다는 이유만으로 모델에서 제거될 수 있다.
5.  불안정성: 데이터가 약간만 바뀌거나, 부트스트랩 표본을 사용하면 완전히 다른 모델이 선택될 수 있다.

결론: 전진/후진 선택법은, 특히 예측 변수 후보가 많을 때, 유용한 모델을 탐색하기 위한 "도구"이지, 최종 모델을 결정하는 "주인"이 되어서는 안 됩니다. 이 방법들을 통해 얻은 결과는 반드시 연구자의 이론적 지식, 상식, 그리고 연구 목적에 비추어 신중하게 해석하고 수정해야 합니다. 통계적 유의성만이 변수 선택의 유일한 기준이 될 수는 없습니다.
