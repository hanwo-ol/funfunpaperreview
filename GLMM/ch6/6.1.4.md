### 6.1.4 예제: 투구게 데이터에 대한 후진 제거법 (Example: Backward Elimination for Horseshoe Crab Data)

[원문 번역]

표 6.2는 예측 변수 너비, 색깔, 가시 상태를 사용하여 투구게 데이터에 여러 로지스틱 모델을 적합시키고 비교한 결과를 요약한다. 적합도에 대한 이탈도($G^2$) 검정은 모델을 포화 모델과 비교한다. 5.2.4절과 5.2.5절에서 언급했듯이, 너비와 같이 예측 변수가 연속형일 때 이것은 근사적으로 카이제곱 분포를 따르지 않는다. 하지만, 적당한 수의 모수만큼 차이 나는 두 모델 간의 이탈도 차이는 의미가 있다. 그 차이는 모델들을 비교하는 우도비 통계량 $-2(L_0 - L_1)$이며, 근사적인 귀무 카이제곱 분포를 갖는다.

모델을 선택하기 위해, 우리는 후진 제거법을 사용하며, 각 단계에서 각 변수에 대한 가장 고차항(highest-order terms)만을 검정한다. 예를 들어, 만약 모델이 어떤 항을 포함하는 상호작용을 가지고 있다면, 그 주효과 항을 제거하는 것은 부적절하다.

우리는 표 6.2의 모델 1인, (C * S * W)로 상징되는 가장 복잡한 모델에서 시작한다. 이 모델은 각 항에 대한 주효과뿐만 아니라 세 개의 이차 상호작용과 삼차 상호작용을 사용한다. 그것은 각 CS 조합에서 개별적인 너비 효과를 허용한다. (사실, 그 조합들 중 일부에서는 한 가지 유형의 y 결과만 발생하여, 그 효과들이 추정 불가능함을 의미한다.) 이 모델을 삼차 상호작용 항을 제거한 더 단순한 모델 (C * S + C * W + S * W)과 비교하는 우도비 통계량은 3.2 (df=3)와 같다. 이는 삼차 항이 필요하지 않음을 시사한다($P=0.36$). 고맙게도, 우리는 단순화 과정을 계속한다.

다음 단계에서 우리는 모델 (C * S + C * W + S * W)을 오직 주효과만 포함하는 더 단순한 모델 C+S+W와 비교한다. 모델을 비교하는 우도비 통계량은 이탈도의 변화량인 $186.61 - 173.68 = 12.9$ (df=166-155=11)이다. 이는 이차 상호작용 항들 또한 필요하지 않음을 시사한다($P=0.30$). 표 6.2는 또한 중간 모델들에 대한 결과들을 보여주며, 한 번에 한 항씩 제거하는 후진 과정 또한 모든 삼차 항들을 제거하는 결과를 낳는다.

다음 단계에서 우리는 주효과 항을 제거하는 것을 고려한다. 표 6.2는 S를 제거하는 것이 거의 결과를 바꾸지 않음을 보여준다. 남은 두 변수(C와 W)는 그때 무시할 수 없는 효과를 갖는다. 예를 들어, C를 제거하면 (모델 7b와 6c를 비교하여) 이탈도가 7.0만큼 증가하고 df=3이다($P=0.07$). 5.4.6절의 분석은 어두운 게(범주 4)와 나머지 게들 사이에 눈에 띄는 차이가 있음을 드러냈다. 색깔에 대해, 어두운 게에 대해 0, 그 외에는 1을 갖는 단일 지시 변수를 가진 더 단순한 모델이 본질적으로 똑같이 잘 적합된다. 추가적인 단순화는 이탈도를 크게 증가시키고 정당화되지 않는다.

---

### 핵심 내용 해설: 복잡한 모델에서 시작하여 가지치기하기

이 예제는 후진 제거법의 실제 적용 과정을 단계별로 보여줍니다. 목표는 네 개의 예측 변수(Color, Spine, Width)와 그들의 모든 가능한 상호작용으로 만들 수 있는 복잡한 모델들 중에서, 데이터를 잘 설명하면서도 가장 간결한(parsimonious) 모델을 찾는 것입니다.

#### 모델 표기법

*   `*`: 상호작용(interaction)과 그를 구성하는 모든 하위 항(주효과 포함)을 의미.
    *   `C*S*W` = `C + S + W + C*S + C*W + S*W + C*S*W`
*   `+`: 주효과(main effects)만을 의미.
    *   `C+S+W`

#### 후진 제거 과정 (단계별 분석)

1단계: 삼차 상호작용(Three-way Interaction) 제거

*   시작 모델(가장 복잡): 모델 1 `(C*S*W)`. 모든 주효과, 이차 상호작용, 삼차 상호작용 포함.
*   비교 대상: 모델 2 `(C*S + C*W + S*W)`. 모델 1에서 삼차 상호작용(`C*S*W`)만 제거.
*   검정: $H_0: \text{삼차 상호작용 효과는 0이다.}$
    *   통계량: $D(\text{모델2}) - D(\text{모델1}) = 173.68 - 170.44 = 3.2$
    *   자유도(df): (모수 개수 차이) = 3
    *   P-값: 0.36
*   결론: P-값이 매우 크므로, 삼차 상호작용 항을 제거해도 모델의 설명력이 거의 나빠지지 않는다. 따라서 삼차 상호작용은 불필요하며, 제거한다.

2단계: 모든 이차 상호작용(Two-way Interactions) 제거

*   시작 모델: 모델 2 `(C*S + C*W + S*W)`.
*   비교 대상: 모델 5 `(C+S+W)`. 모델 2에서 모든 이차 상호작용 항(`C*S`, `C*W`, `S*W`)을 한꺼번에 제거.
*   검정: $H_0: \text{모든 이차 상호작용 효과는 0이다.}$
    *   통계량: $D(\text{모델5}) - D(\text{모델2}) = 186.61 - 173.68 = 12.9$
    *   자유도(df): (모수 개수 차이) = 11
    *   P-값: 0.30
*   결론: P-값이 크므로, 모든 이차 상호작용 항들을 제거해도 모델의 설명력이 유의하게 나빠지지 않는다. 따라서 이차 상호작용들도 불필요하며, 제거한다.
    *(실제 후진 제거법에서는 한 번에 하나씩 가장 유의하지 않은 상호작용 항을 제거하지만, 여기서는 과정을 요약하여 보여주었습니다.)*

3단계: 주효과(Main Effects) 제거

*   시작 모델: 모델 5 `(C+S+W)`. 현재까지 살아남은 가장 단순한 모델.
*   이제 각 주효과를 하나씩 제거해보는 것을 고려한다.
    *   가시 상태(S) 제거: 모델 `(C+W)` (모델 6c) 와 비교.
        *   $D(\text{6c}) - D(\text{5}) = 187.46 - 186.61 = 0.8$ (df=2). P-값이 매우 크다.
        *   결론: 가시 상태(S)는 너비(W)와 색깔(C)이 모델에 있는 상태에서는 추가적인 설명력을 거의 제공하지 못한다. 제거한다.
    *   색깔(C) 제거: 모델 `(S+W)` (모델 6b) 와 비교.
        *   $D(\text{6b}) - D(\text{5}) = 194.42 - 186.61 = 7.8$ (df=3). P-값=0.05.
        *   결론: P-값이 작으므로, 색깔(C)을 제거하면 모델의 설명력이 유의하게 나빠진다. 제거하지 않는다.
    *   너비(W) 제거: 모델 `(C+S)` (모델 6a) 와 비교.
        *   $D(\text{6a}) - D(\text{5}) = 208.83 - 186.61 = 22.2$ (df=1). P-값이 매우 작다.
        *   결론: 너비(W)를 제거하면 모델의 설명력이 매우 크게 나빠진다. 제거하지 않는다.

최종 모델 선택:
*   후진 제거 과정을 통해 색깔(C)과 너비(W)의 주효과만 있는 모델 `(C+W)` (모델 6c)이 잠정적으로 선택된다.
*   추가 분석: 이전 분석에서 색깔의 효과가 주로 '어두운 색'과 '나머지 색'의 차이에서 비롯된 것을 발견했으므로, 색깔을 4개 범주 대신 '어두움 vs. 나머지'라는 2개 범주(하나의 지시 변수)로 단순화한 모델(모델 8)을 고려해 본다.
    *   모델 8 `(C=dark + W)`와 모델 6c `(C+W)`를 비교:
        *   $D(\text{8}) - D(\text{6c}) = 187.96 - 187.46 = 0.5$ (df=2). P-값이 매우 크다.
*   최종 결론: 색깔 변수를 '어두움/기타'로 단순화해도 모델의 적합도가 거의 나빠지지 않는다. 따라서, 데이터를 잘 설명하면서도 가장 간결한 모델은 너비(W)와 이분화된 색깔(C=dark)의 주효과 모델이라고 할 수 있다.

이 예제는 후진 제거법이 어떻게 가장 복잡한 모델에서 시작하여, 통계적으로 유의미하지 않은 항들을 체계적으로 "가지치기"하여 최종적으로 간결하고 해석하기 쉬운 모델을 찾아가는지를 명확하게 보여줍니다.
