### 6.1.5 모델 선택과 "올바른" 모델 (Model Selection and the "Correct" Model)

[원문 번역]

후보 집합에서 모델을 선택할 때, "올바른(correct)" 모델이 하나 있다고 생각한다면 우리는 잘못 생각하는 것이다. 어떤 모델이든 현실의 단순화이다. 예를 들어, 우리가 로짓 연결을 사용하든 항등 연결을 사용하든, 너비는 위성의 확률에 정확히 선형적인 효과를 갖지 않는다.

우리가 그것이 진정으로 성립하지 않는다는 것을 알 때, 모델의 적합도를 검정하는 논리는 무엇인가? 적절하게 맞는 단순한 모델은 모델의 간결성(parsimony)이라는 장점을 갖는다. 만약 모델이 상대적으로 편향이 거의 없고, 현실을 잘 기술한다면, 그것은 관심 있는 양들에 대해 더 정확한 추정치를 제공하는 경향이 있다.

유의성 검정 외의 다른 기준들은 관심 있는 양들을 추정하는 측면에서 좋은 모델을 선택하는 데 도움이 될 수 있다. 우리는 다음에 그러한 기준들 중 가장 잘 알려진 것을 소개한다.

### 6.1.6 AIC: 적합과 실제 간의 거리 최소화 (AIC: Minimizing Distance of the Fit from the Truth)

[원문 번역]

아카이케 정보 기준(Akaike information criterion, AIC)은 어떤 모델의 적합치(fitted values)가 특정 기댓값의 관점에서 실제 평균값에 얼마나 가까운 경향이 있는지를 기준으로 모델을 판단한다. 비록 단순한 모델이 더 복잡한 모델보다 실제 관계로부터 더 멀리 떨어져 있더라도, 그것이 셀 확률과 같은 특정 특성들에 대해 더 나은 추정치를 제공하는 경향이 있기 때문에 선호될 수 있다. 따라서, 최적의 모델은 실제 값에 가장 가까운 적합을 갖는 경향이 있는 모델이다.

아카이케는 쿨백-라이블러(Kullback-Leibler) 거리 측정의 관점에서 근접성을 정의했다. $p(\mathbf{y})$를 실제 모델 하에서의 데이터의 확률(또는 밀도)이라 하고 $p_M(\mathbf{y})$를 선택된 모델 하에서의 확률이라고 하자. 거리 측정은 $E\{\log[p(\mathbf{y})/p_M(\mathbf{y})]\}$이며, 여기서 기댓값은 실제 분포에 대해 취해진다. 범주형 데이터에 대해, 이 측정은 형태상 $G^2$과 유사하다. 표본이 있을 때, 이 기준은 다음을 최소화하는 모델을 선택한다.

$$ \text{AIC} = -2(\text{최대화된 로그우도} - \text{모델의 모수 개수}) $$

이것은 많은 모수를 갖는 모델에 벌점(penalty)을 부과한다. 범주형 Y를 갖는 모델에 대해, 이 순서는 이탈도를 그것의 잔차 자유도의 두 배만큼 조정한, $[G^2 - 2(\text{df})]$에 기반한 순서와 동등하다.

잠재적 예측 변수가 많을 때, 우리는 변수 선택을 돕기 위해 AIC를 사용할 수 있다. 후보 모델 집합 중에서, 우리는 가장 작은 AIC를 가진 모델을 식별한다. 하지만, 비슷한 AIC 값을 가진 모델들도 관심 대상이다. 예를 들어, 우리는 또한 최소값에 비교적 가까운 AIC를 가지면서 더 간결한 모델들을 고려할 것이다.

우리는 표 6.2에 나열된 모델들을 사용하여 모델 선택을 위한 AIC를 설명한다. 그 표는 또한 AIC 값들도 보여준다. 세 가지 기본 변수를 사용하는 모델들 중에서, AIC는 색깔과 너비의 주효과를 갖는 C+W에 대해 가장 작다(AIC=197.5). 게가 어두운지 여부에 대한 지시 변수를 가진 더 단순한 모델은 훨씬 더 좋은 성적을 낸다(AIC=194.0). 어느 모델이든 합리적으로 보인다. 우리는 더 단순한 모델에 대한 더 낮은 AIC와, 그것이 C+W 모델의 적합에 의해 제안되었다는 점 사이에서 균형을 맞춰야 한다.

대안적인 베이지안 정보 기준(Bayesian information criterion, BIC)은 모델의 모수 개수에 대해 더 심하게 벌점을 부과한다. 그것은 모수 개수의 배수로서 2를 $\log(n)$으로 대체하므로, 선택된 모델은 AIC로 선택된 것보다 더 복잡하지 않다. AIC와 비교하여, BIC는 $n$이 증가함에 따라 더 복잡한 모델로 덜 빠르게 이끌린다. 그것은 모델 집합 중 어느 것이 가장 높은 사후 확률(posterior probability)을 갖는지 결정하기 위한 베이지안 논증에 기반하여 유도된다.

---

### 핵심 내용 해설

이 섹션들은 모델 선택 과정의 근본적인 철학과, 유의성 검정(P-값)을 넘어서는 더 정교한 모델 선택 도구인 AIC를 소개합니다.

#### 6.1.5: "정답"은 없다, "유용한" 모델이 있을 뿐

*   조지 박스의 명언: "모든 모델은 틀렸다, 하지만 어떤 것들은 유용하다(All models are wrong, but some are useful)."
*   핵침 철학: 통계 모델은 복잡한 현실 세계를 이해하기 위한 단순화된 근사(simplification)일 뿐, 현실 그 자체가 아닙니다. 따라서 "유일하고 올바른" 모델을 찾는다는 생각은 환상입니다.
*   모델 선택의 목표: "정답"을 찾는 것이 아니라, 주어진 데이터와 연구 목적에 가장 유용한 모델을 찾는 것입니다.
*   "유용한" 모델이란?:
    1.  적절한 적합도(Good Fit): 데이터의 체계적인 패턴을 잘 설명하고, 편향(bias)이 적어야 한다.
    2.  간결성(Parsimony): 불필요하게 복잡하지 않아야 한다. 더 적은 모수를 사용하여 현상을 설명할수록 더 좋다 (오컴의 면도날).
*   간결성의 장점: 단순한 모델은 과적합(overfitting)을 방지하고, 데이터의 무작위적인 노이즈 대신 본질적인 패턴을 포착하여, 새로운 데이터에 대한 더 안정적이고 정확한 예측을 제공하는 경향이 있습니다.

#### 6.1.6: AIC - "예측력"을 위한 모델 선택 기준

*   배경: 유의성 검정(P-값)은 "이 변수가 효과가 있는가?"에만 답할 뿐, 모델의 전반적인 예측 성능을 직접적으로 평가하지는 않습니다.
*   AIC의 철학: "가장 좋은 모델이란, 미래의 새로운 데이터를 가장 잘 예측할 수 있는 모델이다."
    *   이를 수학적으로는 "모델의 적합치"와 "실제 값" 사이의 쿨백-라이블러(K-L) 거리를 최소화하는 것으로 표현합니다.
*   AIC 공식:

$$ \text{AIC} = -2 L + 2p $$

*   $L$: 모델의 최대화된 로그우도 (log-likelihood)
*   $p$: 모델의 모수 개수
*   AIC의 두 가지 요소:
    1.  적합도 항 ($-2L$): $-2L$은 이탈도(Deviance)와 관련이 있으며, 모델이 데이터에 얼마나 잘 맞는지를 나타냅니다. 이 값이 작을수록 적합도가 좋습니다.
    2.  벌점 항 ($2p$): 모델의 복잡도(모수 개수)에 대한 벌점(penalty)입니다. 모수가 많아질수록 이 값은 커집니다.
*   AIC의 작동 원리: AIC는 적합도와 간결성 사이의 균형(trade-off)을 맞추는 역할을 합니다.
    *   모델에 변수를 추가하면 적합도($L$)는 항상 좋아지므로 $-2L$ 항은 감소합니다.
    *   하지만 동시에 모수 개수($p$)가 늘어나므로 벌점 항($2p$)은 증가합니다.
    *   AIC는 이 두 효과를 종합하여, 불필요한 변수를 추가함으로써 얻는 적합도의 작은 이득보다 복잡성에 대한 벌점이 더 커지는 것을 막습니다.
*   사용법:
    1.  여러 후보 모델들에 대해 AIC를 계산한다.
    2.  가장 작은 AIC 값을 갖는 모델을 최적의 모델로 선택한다.
    3.  단, AIC 값이 아주 약간만 차이 나는 모델들(보통 차이가 2 미만)은 거의 동등한 성능을 갖는 것으로 간주하며, 그중 더 간결한 모델을 선호할 수 있다.

*   BIC와의 비교:
    *   BIC는 벌점 항으로 $2p$ 대신 $(\log n)p$를 사용합니다.
    *   표본 크기 $n$이 8 이상이면 $\log n > 2$ 이므로, BIC는 AIC보다 복잡성에 대해 더 강한 벌점을 부과합니다.
    *   따라서 BIC는 AIC보다 더 단순한 모델을 선택하는 경향이 있습니다.

결론: 모델 선택은 복잡한 예술과 같습니다. 후진 제거법 같은 자동화된 절차와 AIC/BIC 같은 정보 기준은 유용한 가이드를 제공하지만, 최종 결정은 항상 연구의 맥락, 이론적 배경, 그리고 모델의 해석 가능성을 종합적으로 고려하여 내려야 합니다. "정답"은 없으며, 주어진 목적에 가장 "유용한" 모델을 찾는 것이 핵심입니다.
