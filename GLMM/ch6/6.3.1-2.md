### 6.3.1 예측력 요약: R과 R-제곱 측도 (Summarizing Predictive Power: R and R-Squared Measures)

[원문 번역]

어떤 GLM에 대해서든, 관측된 반응 $\{y_i\}$와 모델의 적합치 $\{\hat{\mu}_i\}$ 사이의 상관계수 $R(\mathbf{y}, \hat{\boldsymbol{\mu}})$는 예측력을 측정한다. 최소제곱 회귀분석에서, $R$은 Y와 예측 변수들 간의 다중 상관계수이다. 제곱값에 비해 상관계수의 장점은 원래 척도에서 작업하는 매력과 효과 크기에 대한 근사적인 비례성에 있다: 단일 예측 변수를 사용한 작은 효과에 대해, 기울기를 두 배로 하는 것은 대략 $R$을 두 배로 하는 것에 해당한다.

비그룹화 데이터를 사용한 로지스틱 회귀에서, 특정 모델에 대한 $\hat{\mu}_i$는 이항 관측치 $i$에 대한 추정된 확률 $\hat{\pi}_i$이다. 따라서, $R(\mathbf{y}, \hat{\boldsymbol{\mu}})$는 $n$개의 이항 $\{y_i\}$ 관측치(각각 1 또는 0)와 추정된 확률 사이의 상관계수이다. $y$의 매우 이산적인 성격은 가능한 $R$ 값의 범위를 억제할 수 있다. 그럼에도 불구하고, $R$은 동일한 데이터에 대한 다른 모델들의 적합을 비교하는 데 유용하다. 많은 예측 변수가 있을 때 $R$ 추정치는 실제 상관관계 $R(Y, E(Y|\mathbf{X}))$를 추정하는 데 있어 매우 위쪽으로 편향될 수 있다는 주의점이 있으므로, 자유도 값이 크게 다른 모델들의 표본 $R$ 값을 비교하는 것은 오해를 불러일으킬 수 있다. 잭나이프(jackknife) 조정은 이 편향을 줄일 수 있다 (Zheng and Agresti 2000).

이항 반응 $\{y_i\}$와 그것의 적합치 $\{\hat{\pi}_i\}$ 사이의 연관성을 측정하는 또 다른 방법은 제곱 오차의 비례적 감소를 사용하는 것이다.

$$ 1 - \frac{\sum_i(y_i-\hat{\pi}_i)^2}{\sum_i(y_i-\bar{y})^2}, $$

이는 $y_i$의 예측 변수로서 $\bar{y}=\sum_j y_j / n$ 대신 $\hat{\pi}_i$를 사용하여 얻어진다 (Efron 1978). Amemiya (1981)는 역 예측 분산에 의해 제곱 편차에 가중치를 주는 관련 측도를 제안했다. 정규 GLM과 달리, 로지스틱 회귀에 대해, 이들과 $R(\mathbf{y}, \hat{\boldsymbol{\mu}})$는 모델이 더 복잡해짐에 따라 반드시 비감소할 필요는 없다. 어떤 상관관계 유형의 측도처럼, 그것들은 관측된 설명 변수 값들의 범위에 강하게 의존할 수 있으며, 표본 데이터에 대해 계산될 때 대응하는 모집단 측도의 추정치로서 위쪽으로 편향된다.

### 6.3.2 예측력 요약: 우도 및 이탈도 측도 (Summarizing Predictive Power: Likelihood and Deviance Measures)

[원문 번역]

다른 예측력 측도들은 우도 함수를 직접 사용한다. 주어진 모델에 대한 최대화된 로그우도를 $L_M$, 포화 모델에 대한 것을 $L_S$, 그리고 절편 항만 포함하는 귀무 모델(null model)에 대한 것을 $L_0$라고 하자. 확률은 1.0보다 크지 않으므로, 로그우도는 음수가 아니다. 모델 복잡도가 증가함에 따라, 모수 공간이 확장되므로, 최대화된 로그우도는 증가한다. 따라서, $L_0 \le L_M \le L_S \le 0$이다. 측도

$$ \frac{L_M - L_0}{L_S - L_0} \quad (6.3) $$

는 0과 1 사이의 값을 갖는다. 이것은 모델이 귀무 모델보다 적합도에서 개선을 제공하지 않을 때 0과 같고, 모델이 포화 모델만큼 잘 맞을 때 1과 같다. 약점은 로그우도가 쉽게 해석 가능한 척도가 아니라는 점이다. 다른 모델들에 대한 비교적인 의미 외에는, 수치적 값을 해석하기가 어렵다.

$N$개의 독립적인 베르누이 관측치에 대해, 최대화된 로그우도는

$$ \log\left[ \prod_i \hat{\pi}_i^{y_i}(1-\hat{\pi}_i)^{1-y_i} \right] = \sum_i [y_i \log\hat{\pi}_i + (1-y_i)\log(1-\hat{\pi}_i)] $$

이다. 귀무 모델은 $\hat{\pi}_i = (\sum_i y_i)/N = \bar{y}$를 제공하므로,

$$ L_0 = N[\bar{y}\log\bar{y} + (1-\bar{y})\log(1-\bar{y})] $$

이다. 포화 모델은 각 피험자에 대해 모수를 가지며 $\hat{\pi}_i=y_i$임을 의미한다. 따라서, $L_S=0$이고 (6.3)은 다음과 같이 단순화된다.

$$ D = \frac{L_0 - L_M}{-L_0} $$

McFadden(1974)이 이 측도를 제안했다.


---

### 핵심 내용 해설: 로지스틱 회귀의 R-제곱 만들기

일반 선형 회귀분석(OLS)에서 $R^2$은 "모델이 데이터 변동성의 몇 %를 설명하는가?"라는 매우 직관적이고 유용한 정보를 제공합니다. 하지만 로지스틱 회귀에서는 반응 변수 Y가 0 또는 1뿐이어서 "변동성"의 개념이 모호하고, OLS와 같은 깔끔한 $R^2$이 존재하지 않습니다. 이 섹션들은 OLS의 $R^2$ 개념을 모방하려는 다양한 시도, 즉 유사 R-제곱(Pseudo R-Squared) 측도들을 소개합니다.

#### 6.3.1: OLS의 $R^2$을 직접 모방하는 방법들

1.  상관계수 $R(\mathbf{y}, \hat{\boldsymbol{\mu}})$:
    *   아이디어: OLS에서 $R^2$은 (관측값 y)와 (모델 예측값 $\hat{y}$) 사이의 상관계수를 제곱한 것과 같다. 이 아이디어를 그대로 가져오자.
    *   계산: (실제 결과 0 또는 1)과 (모델이 예측한 확률 $\hat{\pi}_i$) 사이의 피어슨 상관계수를 계산한다.
    *   장점: 계산이 간단하고, 여러 모델의 예측력을 상대적으로 비교하는 데 유용하다.
    *   단점: Y가 0/1 값만 가지므로, 상관계수 R의 최댓값이 1에 도달할 수 없다. 따라서 값 자체가 낮게 나오는 경향이 있어 해석이 어렵다.

2.  제곱 오차의 비례적 감소 (Efron's $R^2$):
    *   아이디어: OLS의 $R^2$은 "예측 오차의 감소율"로도 정의된다: $R^2 = 1 - \frac{\sum(y_i-\hat{y}_i)^2}{\sum(y_i-\bar{y})^2}$. 이 공식을 그대로 가져오자.
    *   계산: $\hat{y}_i$ 대신 예측 확률 $\hat{\pi}_i$를, $\bar{y}$ 대신 전체 평균 성공률을 대입한다.
    *   장점: $R^2$의 PRE(오차의 비례적 감소) 개념을 직접적으로 모방하여 직관적이다.
    *   단점: 위의 R과 마찬가지로, 최댓값이 1에 도달하지 못하는 등 이론적 한계가 있다.

#### 6.3.2: 우도를 기반으로 한 R-제곱 유사 측도

이 접근법은 잔차 제곱합 대신, 모델 적합도의 핵심 척도인 로그우도(Log-Likelihood)를 사용합니다.

*   아이디어: "내 모델($M$)이, 아무 정보도 없는 최악의 모델(귀무 모델, $M_0$)과 모든 정보를 다 아는 최상의 모델(포화 모델, $M_S$) 사이의 스펙트럼에서 어디쯤 위치하는가?"

*   구성 요소:
    *   $L_0$ (최악의 적합도): 절편만 있는 모델의 로그우도. 예측 변수 없이, 모든 사람에게 동일한 평균 확률($\bar{y}$)을 예측.
    *   $L_S$ (최상의 적합도): 포화 모델의 로그우도. 모든 관측치를 완벽하게 예측. (비그룹화 이항 데이터의 경우, $\log(1)=0$ 이므로 $L_S=0$).
    *   $L_M$ (내 모델의 적합도): 현재 내가 만든 모델의 로그우도. $L_0 \le L_M \le L_S$ 관계가 성립.

*   측도 (공식 6.3):

$$ R^2_{\text{L}} = \frac{L_M - L_0}{L_S - L_0} $$

*   해석: "내 모델이 귀무 모델 대비 달성한 로그우도 개선량이, 이론적으로 가능한 최대 개선량의 몇 퍼센트인가?"
    *   0과 1 사이의 값을 가지며, 1에 가까울수록 예측력이 좋음을 의미.

*   맥파든의 유사 R-제곱 (McFadden's Pseudo $R^2$):
    *   비그룹화 데이터($L_S=0$)에 대해 위 공식을 적용한 것.
    *   $R^2_{\text{McFadden}} = \frac{L_0 - L_M}{-L_0} = 1 - \frac{L_M}{L_0}$
    *   이탈도($D$)를 사용하면, $D(M_0)=-2L_0$ 이고 $D(M)=-2(L_M-L_S)=-2L_M$ 이므로 (비그룹화 데이터),

$$ R^2_{\text{McFadden}} = \frac{D(M_0) - D(M)}{D(M_0)} $$

형태가 되며, 이는 이탈도의 비례적 감소를 의미한다. 이것이 가장 널리 사용되는 유사 R-제곱 중 하나이다.

중요한 주의사항:
*   이 모든 "유사 R-제곱" 측도들은 OLS의 $R^2$처럼 "모델이 분산의 X%를 설명한다"고 해석할 수 없다.
*   그 값 자체가 절대적인 의미를 갖기보다는, 서로 다른 모델들의 상대적인 예측력을 비교하는 데 주로 사용된다.
*   소프트웨어마다 다른 종류의 유사 R-제곱을 보고할 수 있으므로, 어떤 정의에 기반한 값인지 확인하는 것이 중요하다. (예: Cox & Snell's $R^2$, Nagelkerke's $R^2$ 등)
