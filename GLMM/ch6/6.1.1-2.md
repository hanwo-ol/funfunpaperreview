### 6.1.1 모델에 설명 변수는 몇 개까지 있을 수 있는가? (How Many Explanatory Variables Can Be in the Model?)

[원문 번역]

한쪽 유형의 반응이 상대적으로 적은 불균형 데이터는, 우리가 효과를 효과적으로 추정할 수 있는 예측 변수의 수를 제한한다. 몬테카를로 연구에 기반한 한 가이드라인(Peduzzi et al. 1996)은 예측 변수당 각 유형의 결과 수가 10개 미만일 때, 그 영향으로 심하게 편향된 모수 추정치, 부실한 표준오차 추정치, 그리고 왈드 검정 및 신뢰구간의 오류율이 명목 수준에서 크게 벗어나는 것들이 포함될 수 있다고 제안했다. 예를 들어, 만약 $n=1000$ 중 $y=1$이 30번뿐이라면, 이 가이드라인은 이상적으로 모델이 3개 이하의 예측 변수를 포함해야 함을 의미한다.

이것은 단지 하나의 가이드라인일 뿐이며, 그것을 위반하는 모델을 절대 고려해서는 안 된다는 의미는 아니다. 많은 데이터셋은 이제 표본 크기에 비해 변수의 수가 많다. 7장에서 제시된 특정 전략, 예를 들어 많은 추정치를 0으로 수축시킬 수 있는 벌점화 우도(penalized likelihood) 방법들을 사용하면, 매우 많은 예측 변수를 가질 수 있다. 마찬가지로, 지나치게 야심 차게 되는 것을 정당화하기 위해 그러한 가이드라인을 사용해서는 안 된다. 예를 들어, 만약 각 유형의 결과가 1000개씩 있다면, 보통 100개의 예측 변수를 가진 모델이 좋은 결과를 내지는 않는다.

많은 모델 선택 절차들이 존재하며, 그 중 어느 하나가 항상 최선인 것은 아니다. 보통의 회귀분석에 적용되는 주의사항들은 어떤 일반화 선형 모델에도 적용된다. 예를 들어, 여러 설명 변수를 가진 모델은 다중공선성(multicollinearity)을 보일 수 있다—그들 사이의 상관관계 때문에 모델에 다른 모든 변수가 있을 때 어떤 단일 변수도 중요하지 않은 것처럼 보이게 만든다. 어떤 변수는 모델의 다른 설명 변수들과 상당히 중복되기 때문에, 즉 다른 변수들에 의해 그 자체가 잘 예측되기 때문에 거의 효과가 없는 것처럼 보일 수 있다. 그러한 중복 변수를 삭제하는 것은, 예를 들어 다른 추정된 효과들의 표준오차를 줄이는 데 도움이 될 수 있다.

### 6.1.2 예제: 투구게 짝짓기 데이터 재검토 (Example: Horseshoe Crab Mating Data Revisited)

[원문 번역]

표 4.3의 투구게 데이터셋은 네 가지 설명 변수를 갖는다: 색깔(네 범주), 가시 상태(세 범주), 무게, 그리고 등딱지 너비. 우리는 이제 이 모든 변수들을 사용하여 암컷 게가 근처에 수컷 위성을 가지고 있는지($y=1$)를 예측하는 로지스틱 회귀 모델을 적합시킨다.

우리는 모든 주효과(main effects)를 포함하는 모델을 적합시키는 것으로 시작한다.

$$ \text{logit}[P(Y=1)] = \alpha + \beta_1 \text{weight} + \beta_2 \text{width} + \beta_3 c_1 + \beta_4 c_2 + \beta_5 c_3 + \beta_6 s_1 + \beta_7 s_2 $$

색깔($c_i$)과 가시 상태($s_j$)를 질적 변수(요인)로 취급하며, 처음 세 색깔과 처음 두 가시 상태에 대한 지시 변수를 사용한다. 표 6.1은 결과를 보여준다. Y가 이 예측 변수들과 결합적으로 독립이라는 우도비 검정은 $H_0: \beta_1=\dots=\beta_7=0$을 동시에 검정한다. 검정 통계량은 40.56이고 df=7이다($P<0.0001$). 이것은 적어도 하나의 예측 변수가 효과를 갖는다는 극도로 강력한 증거를 보여준다.

전체적인 검정은 매우 유의하지만, 표 6.1의 결과는 실망스럽다. 무게와 너비에 대한 추정치는 그들의 SE 값보다 단지 약간 더 클 뿐이다. 요인들에 대한 추정치는 각 범주를 마지막 범주와 기준선으로 비교한다. 색깔에 대해서는, 오직 하나의 효과만이 명확하게 유의하다; 가시 상태에 대해서는, 가장 큰 차이도 표준오차보다 작다.

전체 검정에 대한 작은 P-값에도 불구하고, 개별 효과들의 유의성이 부족한 것은 다중공선성의 경고 신호이다. 5.2.2절에서 우리는 너비 효과의 강력한 증거를 보였다. 무게, 색깔, 가시 상태를 통제한 후에는, 너비의 부분 효과(partial width effect)에 대한 증거가 거의 남아있지 않다. 하지만, 무게와 너비는 강한 상관관계(0.887)를 갖는다. 실용적인 목적에서, 그들은 동등하게 좋은 예측 변수들이지만, 둘 모두를 사용하는 것은 거의 중복된다. 우리의 추가 분석은 너비(W)를 색깔(C)과 가시 상태(S)와 함께 설명 변수로 사용한다.

---

### 핵심 내용 해설

이 섹션들은 로지스틱 회귀 모델 구축의 현실적인 문제들, 즉 "어떤 변수를 모델에 넣을 것인가?"와 "몇 개까지 넣을 수 있는가?"에 대해 논의합니다.

#### 6.1.1: 모델의 복잡도 - 경험적 규칙과 다중공선성

*   모델에 변수를 너무 많이 넣으면 안 되는 이유:
    1.  과적합(Overfitting): 모델이 실제 관계가 아닌, 데이터의 무작위적인 노이즈까지 학습하게 되어 새로운 데이터에 대한 예측력이 떨어진다.
    2.  불안정한 추정: 특히 이항 반응에서 한쪽 결과(예: 성공)의 수가 적을 때, 너무 많은 예측 변수를 사용하면 다음과 같은 문제가 발생한다.
        *   회귀 계수($\hat{\beta}$)가 심하게 편향됨.
        *   표준오차(SE)가 부정확해짐.
        *   왈드 검정($z=\hat{\beta}/\text{SE}$)과 신뢰구간을 신뢰할 수 없게 됨.
*   "EPV 10" 규칙 (Events Per Variable):
    *   Peduzzi 등의 연구에서 제안된 경험적인 가이드라인.
    *   "모델에 포함된 예측 변수 1개당, 더 적은 빈도를 가진 결과(성공 또는 실패)가 최소 10개는 있어야 한다."
    *   예시: 심장병 환자(성공)가 30명, 정상인(실패)이 970명인 데이터.
        *   더 적은 결과는 '성공'이고, 30개이다.
        *   이 가이드라인에 따르면, 모델에 포함할 수 있는 예측 변수의 최대 개수는 $30/10 = 3$개이다.
    *   주의: 이는 엄격한 법칙이 아니라, 모델의 안정성을 위한 대략적인 지침이다.

*   다중공선성(Multicollinearity):
    *   정의: 모델에 포함된 예측 변수들끼리 서로 강하게 상관되어 있는 상태. (예: 키와 몸무게, 교육년수와 소득)
    *   증상:
        1.  전체 모델은 유의한데(F-검정 또는 우도비 검정), 개별 계수들은 유의하지 않다.
        2.  회귀 계수의 표준오차(SE)가 매우 커진다.
        3.  데이터를 약간만 바꾸거나 변수를 하나 추가/제거했을 때, 계수 추정치가 극심하게 변한다.
    *   문제점: 어떤 변수가 반응에 "진짜" 영향을 미치는지 구별하기 어렵게 만든다. 변수들의 효과가 서로 얽혀있기 때문이다.

#### 6.1.2: 투구게 예제로 본 다중공선성

*   상황: 4개의 예측 변수(너비, 무게, 색깔, 가시 상태)를 모두 포함한 전체 주효과 모델을 적합.
*   1단계 (전체 모델 유의성 검정):
    *   $H_0: \beta_1=\beta_2=\dots=\beta_7=0$ ("모든 변수가 효과 없음")
    *   우도비 검정 결과, $P<0.0001$. $\implies$ 매우 유의함. "적어도 변수 중 하나는 효과가 있다!"
*   2단계 (개별 계수 유의성 검정):
    *   표 6.1의 각 계수에 대한 P-값을 본다.
    *   너비: $P=0.1779$ (유의하지 않음)
    *   무게: $P=0.2407$ (유의하지 않음)
    *   색깔, 가시상태: 일부만 간신히 유의하거나 유의하지 않음.
*   진단: 전형적인 다중공선성 증상!
    *   전체 모델은 매우 유의한데, 개별 변수들은 대부분 유의하지 않다.
*   원인: 너비(width)와 무게(weight)가 매우 높은 상관관계(0.887)를 갖는다.
    *   두 변수는 거의 동일한 정보를 담고 있다. 모델에 둘 다 넣으면, 컴퓨터는 "너비의 고유한 효과"와 "무게의 고유한 효과"를 분리해내기 어려워한다. 그 결과 두 변수의 표준오차(불확실성)가 모두 커져서, 둘 다 유의하지 않게 보이는 것이다.
*   해결책:
    *   두 변수 중 하나만 사용한다. (이론적으로 더 중요하거나, 측정하기 쉽거나, 단일 변수 모델에서 더 설명력이 좋은 변수 선택)
    *   본문에서는 실용적인 이유로 '너비'를 선택하고 '무게'는 모델에서 제외하기로 결정한다.

결론: 모델을 구축할 때는 단순히 변수를 많이 넣는 것이 능사가 아닙니다. 변수의 개수는 데이터의 정보량(특히 희소한 결과의 수)에 의해 제한되며, 변수들 간의 상관관계(다중공선성)를 반드시 확인하여 모델의 불안정성을 피해야 합니다. "전체는 유의한데 부분은 유의하지 않은" 상황은 다중공선성을 의심해 볼 강력한 신호입니다.
