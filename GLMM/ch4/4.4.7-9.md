### 4.4.7 이항 GLM의 우도 방정식 (Likelihood Equations for Binomial GLMs)

[원문 번역]

$n _i Y _i$가 $\text{bin}(n _i, \pi _i)$ 분포를 따른다고 가정하자. 우리는 4.4.3절의 이항 모수화(parameterization)를 사용하므로, $y _i$는 $n _i$번 시행에 대한 성공의 표본 비율이다. 단일 예측 변수에 대한 이항 GLM (4.8)은 여러 예측 변수들과 함께 다음과 같이 확장된다.

$$ \pi _i = \Phi\left(\sum _j \beta _j x _{ij}\right) \quad (4.26) $$

여기서 $\Phi$는 어떤 연속 분포 종류의 표준 cdf이다. $\pi _i = \mu _i = \Phi(\eta _i)$이고 $\eta _i = \sum _j \beta _j x _{ij}$이므로,

$$ \frac{\partial\mu _i}{\partial\eta _i} = \phi(\eta _i) = \phi\left(\sum _j \beta _j x _{ij}\right) $$

여기서 $\phi(u)=d\Phi(u)/du$ [즉, cdf $\Phi$에 해당하는 pdf이며, (4.17)의 분산 모수가 아님]이다. $\text{var}(Y _i) = \pi _i(1-\pi _i)/n _i$이므로, 우도 방정식 (4.25)는 다음과 같이 단순화된다.

$$ \sum _i \frac{n _i(y _i-\pi _i)x _{ij}}{\pi _i(1-\pi _i)} \phi\left(\sum _j \beta _j x _{ij}\right) = 0, \quad (4.27) $$

여기서 $\pi _i = \Phi(\sum _j \beta _j x _{ij})$이다.

로짓 연결(logit link)에 대해, $\eta _i = \log[\pi _i/(1-\pi _i)]$이므로, $\partial\eta _i/\partial\pi _i=1/[\pi _i(1-\pi _i)]$이고 $\partial\mu _i/\partial\eta _i = \partial\pi _i/\partial\eta _i = \pi _i(1-\pi _i)$이다. 그러면 우도 방정식 (4.27)은 다음과 같이 단순화된다.

$$ \sum _i n _i(y _i-\pi _i)x _{ij} = 0, \quad (4.28) $$

여기서 $\pi _i = \Phi(\sum _j \beta _j x _{ij})$이며 $\Phi$는 표준 로지스틱 cdf이다.

### 4.4.8 모델 모수 추정량의 점근적 공분산 행렬 (Asymptotic Covariance Matrix of Model Parameter Estimators)

[원문 번역]

GLM의 우도 함수는 또한 ML 추정량 $\hat{\boldsymbol{\beta}}$의 점근적 공분산 행렬을 결정한다. 이 행렬은 정보 행렬 $\boldsymbol{\mathcal{I}}$의 역행렬이며, 정보 행렬은 원소 $E[-\partial^2 L(\boldsymbol{\beta})/\partial\beta _h \partial\beta _j]$를 갖는다. 이를 찾기 위해, 로그우도에 대한 기여분 $L _i$에 대해 우리는 다음과 같은 유용한 결과를 사용한다.

$$ E\left(\frac{\partial^2 L _i}{\partial\beta _h \partial\beta _j}\right) = -E\left(\frac{\partial L _i}{\partial\beta _h}\frac{\partial L _i}{\partial\beta _j}\right) $$

이 식은 지수족에 대해 성립한다 (Cox and Hinkley 1974, Sec. 4.8). 따라서, (4.24)로부터,

$$ E\left(\frac{\partial^2 L _i}{\partial\beta _h \partial\beta _j}\right) = -E\left[ \frac{(Y _i-\mu _i)x _{ih}}{\text{var}(Y _i)}\frac{\partial\mu _i}{\partial\eta _i} \frac{(Y _i-\mu _i)x _{ij}}{\text{var}(Y _i)}\frac{\partial\mu _i}{\partial\eta _i} \right] = \frac{-x _{ih}x _{ij}}{\text{var}(Y _i)}\left(\frac{\partial\mu _i}{\partial\eta _i}\right)^2 $$

$L(\boldsymbol{\beta}) = \sum _i L _i$이므로,

$$ E\left(\frac{\partial^2 L(\boldsymbol{\beta})}{\partial\beta _h \partial\beta _j}\right) = -\sum _{i=1}^N \frac{x _{ih}x _{ij}}{\text{var}(Y _i)}\left(\frac{\partial\mu _i}{\partial\eta _i}\right)^2 $$

$\mathbf{W}$를 주대각 원소가 다음과 같은 대각 행렬이라고 하자.

$$ w _i = (\partial\mu _i/\partial\eta _i)^2 / \text{var}(Y _i) \quad (4.29) $$

그러면, 정보 행렬의 일반적인 원소로부터 전체 행렬로 일반화하면,

$$ \boldsymbol{\mathcal{I}} = \mathbf{X}^T \mathbf{W} \mathbf{X} \quad (4.30) $$

이다. $\mathbf{W}$와 그에 따른 $\boldsymbol{\mathcal{I}}$의 형태는 연결 함수에 의존한다는 점에 주목하라.

### 4.4.9 푸아송 로그선형 모델의 우도 방정식과 공분산 (Likelihood Equations and cov(β) for Poisson Loglinear Model)

[원문 번역]

일반적인 푸아송 로그선형 모델 (4.4)은 행렬 형태로 다음과 같다.

$$ \log\boldsymbol{\mu} = \mathbf{X}\boldsymbol{\beta} $$

로그 연결(log link)에 대해, $\eta _i = \log\mu _i$이므로, $\mu _i=\exp(\eta _i)$이고 $\partial\mu _i/\partial\eta _i=\exp(\eta _i)=\mu _i$이다. $\text{var}(Y _i)=\mu _i$이므로, 우도 방정식 (4.25)는 다음과 같이 단순화된다.

$$ \sum _i (y _i - \mu _i)x _{ij} = 0 \quad (4.32) $$

이는 $\boldsymbol{\beta}$에 대한 충분통계량 $\sum _i y _i x _{ij}$를 그들의 기댓값과 동일하게 둔다. 또한,

$$ w _i = (\partial\mu _i/\partial\eta _i)^2/\text{var}(Y _i) = \mu _i^2/\mu _i = \mu _i $$

이므로, $\hat{\boldsymbol{\beta}}$의 추정된 공분산 행렬 (4.31)은 $(\mathbf{X}^T \hat{\mathbf{W}} \mathbf{X})^{-1}$이며, 여기서 $\hat{\mathbf{W}}$는 주대각선에 $\hat{\boldsymbol{\mu}}$의 원소들을 갖는 대각 행렬이다.

---

### 핵심 내용 해설

이 섹션들은 GLM의 일반 이론을 구체적인 모델(이항, 푸아송)에 적용하여, 실제 분석에서 사용되는 핵심 공식들을 유도하는 과정을 보여줍니다.

#### 4.4.7: 이항 GLM 우도 방정식의 구체화

*   일반 우도 방정식 (4.25): $\sum \frac{(y _i-\mu _i)x _{ij}}{\text{var}(Y _i)} \frac{\partial\mu _i}{\partial\eta _i} = 0$
*   이항 GLM에 적용:
    *   $\mu _i = \pi _i$
    *   $\text{var}(Y _i) = \pi _i(1-\pi _i)/n _i$ (여기서 $Y _i$는 비율)
    *   $\frac{\partial\mu _i}{\partial\eta _i}$는 연결 함수에 따라 달라짐.
*   로짓 연결(정준 연결)의 특별함:
    *   로지스틱 회귀의 연결 함수는 로짓, $g(\pi) = \log(\frac{\pi}{1-\pi}) = \eta$ 입니다.
    *   이때 미분 $\frac{\partial\mu _i}{\partial\eta _i} = \frac{\partial\pi _i}{\partial\eta _i}$를 계산하면, 놀랍게도 $\pi _i(1-\pi _i)$가 됩니다.
    *   이것을 일반 우도 방정식에 대입하면:

$$ \sum _i \frac{(y _i-\pi _i)x _{ij}}{\pi _i(1-\pi _i)/n _i} \times [\pi _i(1-\pi _i)] = 0 $$

복잡한 분모와 $\frac{\partial\mu _i}{\partial\eta _i}$ 항이 서로 완벽하게 약분됩니다!
    *   최종 결과 (4.28): $\sum _i n _i(y _i - \pi _i)x _{ij} = 0$.
        *   $n _iy _i$는 $i$번째 그룹의 성공 횟수(관측값), $n _i\pi _i$는 기대 성공 횟수입니다.
        *   이 방정식은 "모든 설명 변수 $x _j$에 대해, 관측된 성공 횟수의 합과 기대 성공 횟수의 합이 같아야 한다"는 매우 직관적인 조건을 의미합니다.
        *   이러한 극적인 단순화는 정준 연결(canonical link)을 사용했을 때 나타나는 마법 같은 속성입니다.

#### 4.4.8: 표준오차는 어디에서 오는가? (점근적 공분산)

*   목표: 모델 모수 추정치 $\hat{\boldsymbol{\beta}}$가 얼마나 불확실한지를 나타내는 분산-공분산 행렬 $\text{cov}(\hat{\boldsymbol{\beta}})$을 구하는 것입니다. 이 행렬의 대각 원소의 제곱근이 바로 각 $\hat{\beta} _j$의 표준오차(SE)가 됩니다.
*   이론: $\text{cov}(\hat{\boldsymbol{\beta}})$는 정보 행렬($\boldsymbol{\mathcal{I}}$)의 역행렬입니다.
*   정보 행렬($\boldsymbol{\mathcal{I}}$) 유도:
    *   정보 행렬의 원소는 $-E[\frac{\partial^2 L}{\partial\beta _h \partial\beta _j}]$ 입니다.
    *   본문은 연쇄 법칙과 우도 이론을 이용하여 이 복잡한 2차 미분의 기댓값을 계산합니다.
    *   최종 결과 (4.30): $\boldsymbol{\mathcal{I}} = \mathbf{X}^T \mathbf{W} \mathbf{X}$
        *   $\mathbf{X}$: 모델 행렬 (우리가 입력한 데이터)
        *   $\mathbf{W}$: 가중치 행렬(weight matrix). 이 행렬의 대각 원소 $w _i = (\frac{\partial\mu _i}{\partial\eta _i})^2 / \text{var}(Y _i)$는 각 관측치가 모수 추정에 얼마나 많은 정보를 제공하는지를 나타냅니다. 분산이 작은 관측치에 더 큰 가중치를 부여합니다.
*   최종 공분산 행렬:

$$ \widehat{\text{cov}}(\hat{\boldsymbol{\beta}}) = \hat{\boldsymbol{\mathcal{I}}}^{-1} = (\mathbf{X}^T \hat{\mathbf{W}} \mathbf{X})^{-1} $$

*   $\hat{\mathbf{W}}$는 $\mu _i$와 $\text{var}(Y _i)$를 추정치로 대체하여 계산한 가중치 행렬입니다.
    *   이 공식은 모든 GLM의 표준오차를 계산하는 일반적인 방법입니다.

#### 4.4.9: 푸아송 모델에 공식 적용하기

*   푸아송 로그선형 모델 (정준 연결):
    *   $\text{var}(Y _i) = \mu _i$
    *   $\eta _i = \log\mu _i \implies \mu _i = e^{\eta _i} \implies \frac{\partial\mu _i}{\partial\eta _i} = e^{\eta _i} = \mu _i$
*   우도 방정식 유도 (4.32):
    *   $\frac{\partial\mu _i}{\partial\eta _i} = \mu _i$ 와 $\text{var}(Y _i) = \mu _i$ 를 일반 우도 방정식 (4.25)에 대입합니다.

$$ \sum _i \frac{(y _i-\mu _i)x _{ij}}{\mu _i} \times \mu _i = \sum _i (y _i-\mu _i)x _{ij} = 0 $$

*   이 역시 정준 연결의 단순화 효과를 보여줍니다. 이 방정식은 "모든 설명 변수 $x _j$에 대해, 관측된 카운트의 합($\sum y _i x _{ij}$)과 기대 카운트의 합($\sum \mu _i x _{ij}$)이 같아야 한다"는 직관적인 조건을 의미합니다.

*   공분산 행렬 유도:
    *   가중치 $w _i = (\frac{\partial\mu _i}{\partial\eta _i})^2 / \text{var}(Y _i) = \mu _i^2 / \mu _i = \mu _i$
    *   따라서, 푸아송 로그선형 모델의 정보 행렬은 $\boldsymbol{\mathcal{I}} = \mathbf{X}^T \mathbf{W} \mathbf{X}$ 이며, 여기서 $\mathbf{W}$는 대각선에 평균 $\mu _i$를 갖는 대각 행렬입니다.
    *   공분산 행렬은 $(\mathbf{X}^T \hat{\mathbf{W}} \mathbf{X})^{-1}$로 계산되며, 여기서 $\hat{\mathbf{W}}$는 대각선에 적합치 $\hat{\mu} _i$를 갖는 행렬입니다.

결론: GLM의 일반 이론은 복잡해 보이지만, 정준 연결을 사용하는 로지스틱 회귀나 푸아송 회귀 같은 중요한 모델들에서는 그 공식이 매우 직관적이고 단순한 형태로 귀결됩니다. 또한, 모든 GLM의 표준
