### **문제 분석 및 모델 설정**

*   **데이터**: $2 \times 2 \times 2$ 분할표의 실제 셀 확률($\pi_{ijk}$)이 주어짐.
    *   $i$: X의 수준 (1, 2)
    *   $j$: Y의 수준 (1, 2)
    *   $k$: Z의 수준 (1, 2)
*   **주어진 확률**:
    *   $Z=1$일 때 ($k=1$):

        | | Y=1 | Y=2 |
        |---|---|---|
        | X=1 | 0.15 | 0.10 |
        | X=2 | 0.10 | 0.15 |

    *   $Z=2$일 때 ($k=2$):

        | | Y=1 | Y=2 |
        |---|---|---|
        | X=1 | 0.10 | 0.15 |
        | X=2 | 0.15 | 0.10 |

*   **반응 변수**: Y

**두 가지 검정 비교**:
1.  **모델 비교 검정**: 모델 $M_1: X+Z$ 와 모델 $M_0: Z$ 를 비교하는 가능도비 검정.
    *   $M_1: \text{logit}[P(Y=1|X=i, Z=k)] = \alpha + \beta^X x_i + \beta_k^Z$ (균일 연관성 모델)
    *   $M_0: \text{logit}[P(Y=1|X=i, Z=k)] = \alpha + \beta_k^Z$ (조건부 독립성 모델)
    *   이 검정은 $H_0: \beta^X = 0$을 검정하는 것과 같습니다.
2.  **적합도 검정**: XY 조건부 독립성 모델($M_0$)의 적합도 검정.
    *   $M_0$를 포화 모델($M_{sat}$)과 비교하는 검정입니다.

**질문**: 왜 1번 검정은 consistent하지 않지만, 2번 검정은 consistent한가?
*   **Consistent Test**: 귀무가설이 거짓일 때, 표본 크기 $n$이 무한대로 감에 따라 검정력이 1로 수렴하는 검정. 즉, 표본이 충분히 크면 거짓인 귀무가설을 반드시 기각해내는 검정.

---

### **식 (Formulation)**

검정의 일관성(consistency)은 대립가설이 참일 때, 검정 통계량의 **비중심성 모수(noncentrality parameter, $\lambda$)**가 0보다 큰지에 따라 결정됩니다. $\lambda > 0$ 이면, $n \to \infty$ 일 때 검정력이 1로 수렴하므로 검정은 consistent 합니다.

**1. 주어진 확률값으로부터 조건부 오즈비 계산**

먼저, 주어진 확률값으로부터 각 Z 수준에서의 조건부 오즈비를 계산하여 실제 연관성 구조를 파악합니다.
*   **Z=1일 때**:

$$ \theta_{XY(1)} = \frac{\pi_{111}\pi_{221}}{\pi_{121}\pi_{211}} = \frac{0.15 \times 0.15}{0.10 \times 0.10} = \frac{0.0225}{0.01} = 2.25 $$

*   **Z=2일 때**:

$$ \theta_{XY(2)} = \frac{\pi_{112}\pi_{222}}{\pi_{122}\pi_{212}} = \frac{0.10 \times 0.10}{0.15 \times 0.15} = \frac{0.01}{0.0225} = 1/2.25 \approx 0.444 $$

*   **관찰**: 조건부 오즈비가 1이 아니므로 **조건부 독립성은 성립하지 않습니다**. 또한, $\theta_{XY(1)} \neq \theta_{XY(2)}$ 이므로 **균일 연관성도 성립하지 않습니다**. 연관성의 방향이 Z 수준에 따라 반대입니다 (상호작용 존재).

**2. 모델 비교 검정의 일관성 분석**

*   **검정 통계량**: $G^2(M_0|M_1) = -2(L_0 - L_1)$
*   **비중심성 모수 ($\lambda_{M_0|M_1}$)**:

$$ \lambda_{M_0|M_1} = 2n \sum_{i,j,k} \pi_{ijk} \log\left(\frac{\pi_{ijk}(M_1)}{\pi_{ijk}(M_0)}\right) $$

    여기서 $\pi_{ijk}(M)$은 모델 M 하에서의 예측 확률입니다.

*   **핵심**: 모델 $M_1$(X+Z)은 **균일 연관성**을 가정합니다. 하지만 실제 확률은 균일하지 않고 상호작용이 존재합니다. 따라서 $M_1$은 **잘못 명시된 모델(misspecified model)**입니다.
*   $M_1$과 $M_0$ 모두 실제 확률 구조를 제대로 반영하지 못합니다. 이 경우, 두 잘못된 모델 간의 K-L 거리를 비교하게 됩니다. 주어진 확률 구조의 대칭성 때문에, $M_1$ 모델을 적합시키면 $\beta^X$의 추정치는 0에 매우 가깝게 나옵니다. 즉, $M_1$의 예측 확률 $\pi(M_1)$과 $M_0$의 예측 확률 $\pi(M_0)$이 거의 같아집니다.
*   결과적으로, $\log(\pi(M_1)/\pi(M_0))$ 항이 거의 0에 가까워져서, **비중심성 모수 $\lambda_{M_0|M_1}$가 0이 됩니다.**
*   $\lambda=0$ 이므로, $n$이 아무리 커져도 검정력은 유의수준 $\alpha$를 넘지 못합니다. 따라서 이 검정은 **consistent하지 않습니다.**

**3. 적합도 검정의 일관성 분석**

*   **검정 통계량**: $G^2(M_0) = -2(L_0 - L_{sat})$
*   **비중심성 모수 ($\lambda_{M_0}$)**:

$$ \lambda_{M_0} = 2n \sum_{i,j,k} \pi_{ijk} \log\left(\frac{\pi_{ijk}}{\pi_{ijk}(M_0)}\right) $$

    여기서 분자의 $\pi_{ijk}$는 실제 확률(포화 모델의 예측)입니다.

*   **핵심**: 귀무가설($M_0$, 조건부 독립성)은 실제 확률 구조와 다릅니다. 즉, $\pi_{ijk} \neq \pi_{ijk}(M_0)$ 입니다.
*   예를 들어, $Z=1, X=1, Y=1$일 때, $\pi_{111}=0.15$ 입니다. 반면, $M_0$ 하에서의 예측 확률 $\pi_{111}(M_0) = \pi_{+11} \times \pi_{1+1} / \pi_{++1}$ 은 다른 값을 가집니다.
*   따라서 $\log(\pi_{ijk}/\pi_{ijk}(M_0))$ 항이 0이 아니며, 전체 합도 0이 아닙니다.
*   결과적으로, **비중심성 모수 $\lambda_{M_0}$는 0보다 큽니다 ($\lambda_{M_0} > 0$)**.
*   $\lambda > 0$ 이므로, $n \to \infty$ 일 때 검정력은 1로 수렴합니다. 따라서 이 검정은 **consistent 합니다.**

---

### **R 코드 (R Code)**

이 문제는 이론적인 질문이므로, R 코드는 주어진 확률을 "모집단"으로 간주하고, 이 모집단에 각 모델을 적합시켰을 때 예측 확률이 어떻게 나오는지를 시뮬레이션하여 위 설명을 뒷받침하는 방식으로 작성됩니다.

```R
# 1. 주어진 확률값으로 데이터 프레임 생성
prob_data <- data.frame(
  X = factor(c(1, 2, 1, 2, 1, 2, 1, 2)),
  Y = factor(c(1, 1, 2, 2, 1, 1, 2, 2)),
  Z = factor(c(1, 1, 1, 1, 2, 2, 2, 2)),
  prob = c(0.15, 0.10, 0.10, 0.15, 0.10, 0.15, 0.15, 0.10)
)

# 매우 큰 표본 크기를 가정 (n=1,000,000)
n_total <- 1000000
prob_data$counts <- prob_data$prob * n_total

# 2. 각 모델 적합
# Y를 0/1로 변환 (Y=1이 성공)
prob_data$Y_numeric <- ifelse(prob_data$Y == 1, 1, 0)

# M1: X+Z 모델 (균일 연관성 모델)
# weights 인자를 사용하여 각 행의 빈도 지정
model_1 <- glm(Y_numeric ~ X + Z, data = prob_data, family = binomial, weights = counts)

# M0: Z 모델 (조건부 독립성 모델)
model_0 <- glm(Y_numeric ~ Z, data = prob_data, family = binomial, weights = counts)

# 3. 각 모델의 예측 확률 계산
prob_data$pi_M1 <- predict(model_1, type = "response")
prob_data$pi_M0 <- predict(model_0, type = "response")

# 4. 비중심성 모수(lambda) 계산

# 람다 계산 함수
calculate_lambda <- function(pi_true, pi_model, n) {
  # pi_true와 pi_model은 성공 확률이므로, 결합 확률로 변환해야 함
  # 주변 확률 계산
  pi_xz_marginals <- aggregate(pi_true, by = list(prob_data$X, prob_data$Z), FUN = sum)
  
  # 결합 확률 계산
  p_ijk_true <- ifelse(prob_data$Y_numeric == 1, pi_true, 1 - pi_true) * pi_xz_marginals$x[match(paste(prob_data$X, prob_data$Z), paste(pi_xz_marginals$Group.1, pi_xz_marginals$Group.2))]
  p_ijk_model <- ifelse(prob_data$Y_numeric == 1, pi_model, 1 - pi_model) * pi_xz_marginals$x[match(paste(prob_data$X, prob_data$Z), paste(pi_xz_marginals$Group.1, pi_xz_marginals$Group.2))]
  
  # 0인 확률 방지
  p_ijk_true[p_ijk_true == 0] <- 1e-10
  p_ijk_model[p_ijk_model == 0] <- 1e-10
  
  lambda <- 2 * n * sum(p_ijk_true * log(p_ijk_true / p_ijk_model))
  return(lambda)
}

# 람다_M0|M1 계산
# 이 경우 pi_true는 M1의 예측 확률, pi_model은 M0의 예측 확률
lambda_M0_M1 <- calculate_lambda(prob_data$pi_M1, prob_data$pi_M0, n_total)

# 람다_M0 계산
# 이 경우 pi_true는 실제 확률, pi_model은 M0의 예측 확률
lambda_M0 <- calculate_lambda(prob_data$prob, prob_data$pi_M0, n_total)


# 5. 결과 출력
print("--- 모델 비교 검정 (M0 vs M1) ---")
print(paste("비중심성 모수 (lambda_M0|M1):", lambda_M0_M1))

print("--- 적합도 검정 (M0 vs Msat) ---")
print(paste("비중심성 모수 (lambda_M0):", lambda_M0))

# anova 함수로 직접 검정 수행 (n이 크므로 점근적 결과와 유사)
lrt_M0_M1 <- anova(model_0, model_1, test = "LRT")
print("--- anova(M0, M1) 결과 ---")
print(lrt_M0_M1)

# M0의 적합도 검정 (이탈도)
gof_M0 <- anova(model_0, test = "LRT")
print("--- anova(M0) 적합도 검정 결과 ---")
print(gof_M0)
```
