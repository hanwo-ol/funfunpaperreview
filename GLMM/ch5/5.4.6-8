### 5.4.6 순서형 예측 변수의 양적 처리 (Quantitative Treatment of Ordinal Predictor)

[원문 번역]

색깔은 가장 밝은 것부터 가장 어두운 것까지 순서화된 범주들을 갖는다. 더 단순한 모델은 이 예측 변수를 양적으로 취급한다. 색깔은, 어떤 단조로운 점수 집합에 대해, 선형 효과를 가질 수 있다. 예를 들어, 색깔 범주에 대한 점수 $c=(1,2,3,4)$에 대해, 모델

$$ \text{logit}[P(Y=1)] = \alpha + \beta _1 c + \beta _2 x \quad (5.14) $$

는 $\hat{\alpha}=-10.071, \hat{\beta} _1=-0.509 (\text{SE}=0.224), \hat{\beta} _2=0.458 (\text{SE}=0.104)$를 갖는다. 이것은 각각의 효과에 대한 강한 증거를 보여준다. 주어진 너비에서, 색깔의 어두움이 한 범주 증가할 때마다, 위성의 추정된 오즈는 $\exp(-0.509)=0.60$배 곱해진다.


각 색깔에 대해 별도의 모수를 갖는 더 복잡한 모델 (5.13)과 이 적합을 비교하는 우도비 통계량은 1.66 (df=2)이다. 이 통계량은 모델 (5.13)이 성립한다고 주어졌을 때, 더 단순한 모델 (5.14)이 적절한지 검정한다. 그것은 색깔 점수에 대해 플로팅했을 때, (5.13)의 색깔 모수들이 선형 추세를 따르는지 검정한다. 이 단순화는 허용 가능한 것으로 보인다 ($P=0.44$).

질적-색깔 모델 (5.13)의 색깔 모수 추정치들은 (1.33, 1.40, 1.11, 0)이며, 0 값은 어두운 범주가 지시 변수를 갖지 않음을 반영한다. 비록 이 값들이 선형 추세에서 유의하게 벗어나지는 않지만, 처음 세 개는 마지막 것과 비교할 때 꽤 비슷하다. 따라서, 모델 (5.14)에 대한 또 다른 잠재적인 색깔 점수 부여는 (1,1,1,0)이다; 즉, 어두운 색 게에 대해 점수=0, 그 외에는 점수=1이다. 이 이항 점수를 사용하여 모델 (5.14)를 모델 (5.13)과 비교하는 우도비 통계량은 0.50 (df=2)과 같으며, 이 더 단순한 모델 또한 적절함을 보여준다. 그것의 적합은

$$ \text{logit}[\hat{P}(Y=1)] = -12.980 + 1.300c + 0.478x \quad (5.15) $$

이며, 표준오차는 0.526과 0.104이다. 주어진 너비에서, 더 밝은 색 게가 위성을 가질 추정된 오즈는 어두운 게의 추정된 오즈의 $\exp(1.300)=3.7$배이다. 요약하면, 질적-색깔 모델, 점수 (1,2,3,4)를 사용한 양적-색깔 모델, 그리고 이항 색깔 점수 (1,1,1,0)를 사용한 모델 모두 어두운 게가 위성을 가질 가능성이 가장 낮다는 것을 시사한다. 어떤 색깔 점수 부여가 가장 적절한지 결정하기 위해서는 훨씬 더 큰 표본이 필요하다. 중간 크기의 표본에서는, 상당히 다른 모델들이 데이터와 일관적인 것은 드문 일이 아니다.

### 5.4.7 확률 기반 및 표준화된 해석 (Probability-Based and Standardized Interpretations)

[원문 번역]

비록 로지스틱 회귀 모델 모수를 로그 오즈에 대한 효과로 해석하는 것이 자연스럽지만, 일부 사람들은 오즈 또는 오즈비 효과를 이해하기 어려워한다. 확률의 순간 변화율을 사용하는 더 간단한 해석(5.1.1절)은 다중 예측 변수에도 적용된다. ...

$x _j$의 효과를 그 단위에 의존하지 않는 더 간단한 방식으로 기술하기 위해, 우리는 다른 예측 변수들을 그들의 표본 평균에 고정시키고, $x _j$의 가장 작은 값과 가장 큰 값에서의 추정된 확률을 계산할 수 있다. 하지만 이것들은 이상치에 민감하므로, 대신 $x _j$의 상위 및 하위 사분위수를 사용할 수 있다. 이항 색깔을 사용한 적합 (5.15)에 대해, 표본 평균은 너비 $x$에 대해 26.3이고 색깔 $c$에 대해 0.873이다. $x$의 하위 및 상위 사분위수는 24.9와 27.7이다. $x=24.9, c=\bar{c}$일 때, $\hat{\pi}=0.51$이다. $x=27.7, c=\bar{c}$일 때, $\hat{\pi}=0.80$이다. 너비 값 범위의 중간 50%에 걸쳐 $\hat{\pi}$가 0.51에서 0.80으로 변하는 것은 강한 너비 효과를 반영한다. $c$는 0과 1의 값만 가지므로, 우리는 대신 이 효과를 각각에 대해 따로 보고할 수 있다. 또한, 설명 변수가 지시 변수일 때, 동일할 수 있는 사분위수 대신 그것의 두 값에서의 추정된 확률을 보고하는 것이 합리적이다. $\bar{x}=26.3$에서, $c=0$일 때 $\hat{\pi}=0.40$이고 $c=1$일 때 $\hat{\pi}=0.71$이다. 다른 것들과 어두운 게를 구별하는 이 색깔 효과 또한 상당하다.

### 5.4.8 평균 인과 효과 추정하기 (Estimating an Average Causal Effect)

[원문 번역]

많은 응용 분야에서 주요 관심 설명 변수는 모델의 다른 설명 변수들을 통제하면서 비교할 두 그룹을 명시한다. $j=1$이 이 이항 그룹 변수를 식별하고, 그룹은 $x _1=0$과 $x _1=1$로 표기된다고 하자. 로지스틱 회귀 모델에 대해, 효과 요약으로서의 로그 오즈비 $\beta _1$에 대한 대안은 추정된 평균 인과 효과(average causal effect)이다.

$$ \frac{1}{n}\sum _i [\hat{\pi}(x _{i1}=1, x _{i2}, \dots, x _{ip}) - \hat{\pi}(x _{i1}=0, x _{i2}, \dots, x _{ip})] $$

각 관측치 $i$에 대해, 우리는 (1) 만약 그 관측치가 그룹 1에 있었다면, 그리고 (2) 만약 그 관측치가 그룹 0에 있었다면의 주어진 $x _{i2}, \dots, x _{ip}$ 값들에 대한 적합 확률을 찾고, 모든 $n$개의 관측치에 걸쳐 그 차이들을 평균낸다. 이것은 연구의 모든 피험자들이 그룹 0에 있었을 때와 비교하여 모두 그룹 1에 있었을 경우의 "성공"의 전체 비율 간의 차이를 추정한다.

---

### 핵심 내용 해설

이 섹션들은 다중 로지스틱 회귀를 더 정교하게 만들고, 그 결과를 더 쉽게 이해할 수 있도록 해석하는 고급 기법들을 소개합니다.

#### 5.4.6: 순서형 변수를 다루는 현명한 방법

*   문제: 예측 변수가 "음주량(없음, 약간, 보통, 많음)"과 같이 순서가 있지만, 범주 간의 간격이 일정하지 않은 순서형(ordinal) 변수일 때 어떻게 해야 하는가?
*   방법 1 (명목형 취급): 가장 간단하지만 비효율적. 순서 정보를 무시하고 지시 변수 사용. (5.3절)
*   방법 2 (양적 취급, 본문 내용): 더 효율적. 범주에 적절한 점수(scores)를 부여하여 하나의 양적 변수처럼 취급.

$$ \text{logit}(\pi _i) = \alpha + \beta x _i $$

*   점수 선택:
        1.  등간격 점수 (1,2,3,4,...): 가장 간단. 범주 간 간격이 비슷하다고 가정.
        2.  이론 기반 점수: "없음=0잔, 약간=0.5잔, 보통=1.5잔, ..." 과 같이 실제 값에 기반한 점수. (투구게 예제)
        3.  데이터 기반 점수: (1,1,1,0)처럼 데이터를 보고 비슷한 범주들을 묶어 점수화.
    *   장점: 모수의 개수를 줄여 모델을 간결하게(parsimonious) 만들고, 순서 정보를 활용하여 검정력을 높인다.
    *   모델 비교: 더 복잡한 명목형 모델(방법 1)과 더 단순한 양적 모델(방법 2)을 우도비 검정으로 비교하여, 이러한 단순화가 통계적으로 타당한지 확인할 수 있다.

#### 5.4.7: 오즈비가 어려울 때를 위한 해석법

*   문제: "오즈가 3.7배 증가한다"는 말은 통계학자가 아닌 사람들에게는 와닿지 않는다.
*   해결책: 효과를 확률(probability)의 변화로 번역하여 제시한다.
    1.  특정 시나리오 제시: 다른 예측 변수들은 평균값 등으로 고정시킨다.
    2.  확률 변화 계산: 관심 있는 예측 변수의 값을 변화시키면서(예: 하위 사분위수 $\to$ 상위 사분위수) 예측 확률 $\hat{\pi}$가 얼마나 변하는지 직접 계산하여 보여준다.
        *   투구게 예제: "평균 색깔의 게에서, 너비가 24.9cm에서 27.7cm로 증가할 때, 위성을 가질 확률은 51%에서 80%로 29%p 증가한다."
    3.  장점: 효과의 크기를 실제적인 맥락에서 매우 직관적으로 전달할 수 있다.

#### 5.4.8: 인과관계에 대한 더 나은 추정치, ACE

*   문제: 로지스틱 회귀에서 $\beta _1$ (또는 오즈비 $e^{\beta _1}$)은 효과의 크기를 나타내지만, 그 크기는 모든 사람에게 동일하지 않다 (비선형 모델이므로). 전체 인구에 대한 평균적인 효과는 얼마일까?
*   평균 인과 효과 (Average Causal Effect, ACE):
    *   아이디어: "모든 사람이 치료를 받았다면 성공률이 어땠을까?"와 "모든 사람이 치료를 받지 않았다면 성공률이 어땠을까?"의 차이를 계산한다.
    *   계산 과정:
        1.  각 개인 $i$에 대해, 모델을 사용하여 두 가지 가상 시나리오의 확률을 예측한다.
            *   $\hat{\pi} _i(\text{치료 받음})$
            *   $\hat{\pi} _i(\text{안 받음})$
        2.  각 개인에 대한 치료 효과($\hat{\pi} _i(\text{치료 받음}) - \hat{\pi} _i(\text{안 받음})$)를 계산한다.
        3.  이 개별 효과들을 모든 사람에 대해 평균낸다.
*   장점:
    *   효과의 크기를 비율 차이라는 매우 해석하기 쉬운 단일 숫자로 요약해준다. (예: "AZT 치료는 AIDS 발현 확률을 평균적으로 11.45%포인트 낮춘다.")
    *   실험 연구(RCT)에서 인과적 효과를 요약하는 자연스러운 방법이며, 관찰 연구에서도 성향 점수(propensity score) 등과 결합하여 널리 사용된다.

종합 요약: 이 섹션들은 로지스틱 회귀 모델을 분석의 끝이 아닌 시작으로 삼아, 1) 순서형 변수를 더 정교하게 다루어 모델의 효율성을 높이고, 2) 복잡한 결과를 확률 변화와 같은 직관적인 언어로 번역하며, 3) 전체 표본에 대한 평균적인 효과 크기를 요약하는 등, 더 깊이 있고 실용적인 통찰을 얻는 방법들을 제시합니다.
