 **스코어 검정(Score Test)**에 대해 설명하고 있습니다.

### 스코어 검정의 핵심 아이디어: "정상에서 얼마나 멀리 밀어야 하는가?"

스코어 검정의 근본적인 질문을 비유적으로 표현하면 다음과 같습니다.

> **"만약 귀무가설($H_0$)이 주장하는 지점($\beta_0$)이 로그우도 언덕의 진짜 정상이라면, 그 지점은 평평해야 할 것이다. 그런데 실제 데이터로 계산해 보니, 그 지점이 얼마나 가파른가?"**

이 아이디어를 더 자세히 살펴보겠습니다.

1.  **로그우도 언덕의 정상**: 로그우도 함수 $L(\beta)$를 하나의 언덕으로 상상해 보세요. 이 언덕의 가장 높은 지점, 즉 **정상**은 최대우도 추정량($\hat{\beta}$)이 위치한 곳입니다. 수학적으로, 정상에서는 **기울기가 0**입니다. ($ \partial L(\beta) / \partial \beta |_{\beta=\hat{\beta}} = 0 $)

2.  **귀무가설의 주장**: 귀무가설 $H_0: \beta = \beta_0$는 "언덕의 진짜 정상은 $\beta_0$에 있다"고 주장하는 것과 같습니다.

3.  **스코어 검정의 논리**: 만약 귀무가설의 주장이 사실이라면, $L(\beta)$를 $\beta_0$에서 계산했을 때 그 지점의 기울기는 0에 매우 가까워야 합니다. 그런데 만약 실제 데이터로 계산한 기울기가 0에서 매우 멀다면 (즉, 그 지점이 매우 가파르다면), 이는 "귀무가설이 주장하는 지점은 정상이 아니다"라는 강력한 증거가 됩니다.

스코어 검정은 바로 이 **"귀무가설 지점에서의 기울기"**를 측정하여 가설을 검정하는 방법입니다.

---

### 스코어 통계량의 구성 요소

스코어 검정 통계량은 두 가지 핵심 요소로 구성됩니다. 모두 **귀무가설 값 $\beta_0$에서** 계산된다는 점이 가장 큰 특징입니다.

#### 1. 스코어 함수 (Score Function), $u(\beta_0)$: 기울기

$$ u(\beta_0) = \left. \frac{\partial L(\beta)}{\partial \beta} \right|_{\beta=\beta_0} $$

*   이것은 로그우도 함수를 모수 $\beta$에 대해 한 번 미분한 함수(도함수)이며, **기울기**를 나타냅니다.
*   $u(\beta_0)$는 귀무가설이 주장하는 지점($\beta_0$)에서의 로그우도 언덕의 **가파른 정도**를 나타내는 값입니다.
*   $u(\beta_0)$의 **절댓값이 클수록**, 귀무가설 지점은 평평한 정상에서 멀리 떨어져 있다는 의미이므로, 귀무가설에 대한 강력한 반박 증거가 됩니다.

#### 2. 피셔 정보 (Fisher Information), $ι(\beta_0)$: 예상 곡률 (표준화 척도)

$$ ι(\beta_0) = -E\left[ \left. \frac{\partial^2 L(\beta)}{\partial \beta^2} \right|_{\beta=\beta_0} \right] $$

*   단순히 기울기($u(\beta_0)$)의 크기만으로는 충분하지 않습니다. "얼마나 가파른 것이 통계적으로 의미 있는가?"를 판단할 **기준(잣대)**이 필요합니다.
*   이 역할을 하는 것이 바로 피셔 정보, 즉 로그우도 언덕의 **예상 곡률**입니다.
    *   **곡률이 크다 (언덕이 뾰족하다)**: 모수에 대한 정보가 많다. 이런 상황에서는 기울기가 조금만 0에서 벗어나도 통계적으로 매우 유의미합니다.
    *   **곡률이 작다 (언덕이 평평하다)**: 모수에 대한 정보가 적다. 이런 상황에서는 기울기가 꽤 커도 우연히 발생한 것일 수 있습니다.
*   $ι(\beta_0)$는 귀무가설 하에서 스코어(기울기)가 얼마나 변동할 수 있는지를 나타냅니다. 구체적으로, **스코어의 분산(variance)이 바로 피셔 정보**와 같습니다. ($ \text{Var}[u(\beta_0)] = ι(\beta_0) $)
*   따라서 스코어의 표준편차(즉, 표준오차)는 $ \sqrt{ι(\beta_0)} $ 가 됩니다.

---

### 최종 스코어 통계량

이제 두 요소를 결합하여 최종 통계량을 만듭니다.

*   **정규분포 형태 (z-statistic)**:
    $$ z_s = \frac{u(\beta_0)}{\sqrt{ι(\beta_0)}} = \frac{\text{귀무가설 지점에서의 기울기}}{\text{기울기의 표준편차}} $$
    이것은 "귀무가설 지점의 기울기가 표준편차의 몇 배만큼 0에서 떨어져 있는가?"를 측정하며, 근사적으로 **표준정규분포**를 따릅니다.

*   **카이제곱 형태 ($\chi^2$-statistic)**:
    $$ \chi^2_s = \frac{[u(\beta_0)]^2}{ι(\beta_0)} $$
    위의 정규분포 형태를 제곱한 것으로, 근사적으로 **자유도 1인 카이제곱 분포**를 따릅니다.

### 세 가지 검정 방법의 비교 (그림 1.1의 의미)

텍스트의 마지막 부분은 세 가지 검정 방법이 로그우도 언덕의 **어느 지점의 정보**를 사용하는지를 요약합니다. 이는 세 검정의 철학적 차이를 명확하게 보여줍니다. ($H_0: \beta=0$을 예로)

1.  **왈드 검정 (Wald Test)**
    *   **사용 지점**: 언덕의 **정상($\hat{\beta}$)**.
    *   **논리**: "정상($\hat{\beta}$)이 0에서 얼마나 멀리 떨어져 있는가?"를 **정상에서의 곡률(SE)**을 기준으로 평가.

2.  **스코어 검정 (Score Test)**
    *   **사용 지점**: **귀무가설 지점(0)**.
    *   **논리**: "귀무가설 지점(0)이 얼마나 가파른가?"를 **그 지점에서의 곡률**을 기준으로 평가.

3.  **우도비 검정 (Likelihood-Ratio Test)**
    *   **사용 지점**: **정상($\hat{\beta}$)과 귀무가설 지점(0) 모두**.
    *   **논리**: "정상의 높이($L_1$)와 귀무가설 지점의 높이($L_0$)의 **차이**가 얼마나 큰가?"를 평가. (그림 1.1의 수직 거리)

### 스코어 검정의 실용적 장점

스코어 검정은 때때로 매우 유용한 장점을 가집니다. 바로 **축소 모델(귀무가설 모델)만 적합시키면 된다**는 점입니다. 왈드 검정과 우도비 검정은 전체 모델(대립가설 모델)을 적합시켜서 $\hat{\beta}$를 구해야 하지만, 스코어 검정은 그럴 필요가 없습니다. 이는 특히 전체 모델이 매우 복잡하고 계산 비용이 많이 드는 경우에 큰 이점이 될 수 있습니다.
