
### 1.3.3 왈드-우도비-스코어 검정 (Wald–Likelihood Ratio–Score Test Triad)

대표본(large-sample) 추론을 수행하기 위해 우도 함수를 사용하는 세 가지 표준적인 방법이 있습니다. 여기서는 귀무가설 $H_0: \beta = \beta_0$를 검정하는 방법을 소개하고, 그 후 구간 추정과의 관계를 논의하겠습니다. 이 방법들은 모두 최대우도(ML) 추정량의 대표본 정규성을 활용합니다.

표준오차는 정보 행렬의 역행렬로부터 얻어지며 미지의 모수 값에 의존합니다. 귀무가설을 가정하지 않고 구한 ML 추정값을 대입하여 얻은 $\hat{\beta}$의 추정된 표준오차를 SE라고 표기하겠습니다. $-E[\partial^2L(\beta)/\partial\beta^2]$ (즉, 정보)를 $\hat{\beta}$에서 계산한 값을 $ι(\hat{\beta})$로 나타냅시다. 첫 번째 대표본 추론 방법은 이 추정된 표준오차를 사용하는 검정 통계량을 가집니다.

$$ z = (\hat{\beta} - \beta_0) / \text{SE}, \quad \text{여기서 } \text{SE} = 1/\sqrt{ι(\hat{\beta})} $$

이 통계량은 $\beta = \beta_0$일 때 근사적으로 표준정규분포를 따릅니다. 우리는 표준정규분포표를 참조하여 단측 또는 양측 P-값을 얻습니다. 이와 동등하게, 양측 대립가설에 대해서는 $z^2$이 근사적으로 자유도(df)가 1인 카이제곱 귀무분포를 따릅니다. 이때 P-값은 관측된 값보다 큰 카이제곱 확률의 오른쪽 꼬리 면적이 됩니다. 이와 같이 귀무가설 하에서가 아닌 (nonnull) 추정된 표준오차를 사용하는 통계량을 왈드 통계량(Wald statistic)이라고 부릅니다 (Wald 1943).

귀무가설 $H_0: \mathbf{\beta} = \mathbf{\beta_0}$에 대한 왈드 검정의 다변량 확장은 다음과 같은 검정 통계량을 가집니다.

$$ W = (\hat{\beta} - \beta_0)^T [\text{cov}(\hat{\beta})]^{-1} (\hat{\beta} - \beta_0) $$

여기서 nonnull 공분산은 $\hat{\beta}$에서의 로그우도 함수 곡률(1.6)에 기반하며, 일반적으로 추정이 필요합니다. $\hat{\beta}$의 점근적 다변량 정규분포는 $W$가 점근적으로 카이제곱 분포를 따름을 의미합니다. 자유도(df)는 $\text{cov}(\hat{\beta})$의 계수(rank)와 같으며, 이는 $\beta$에서 중복되지 않는 모수의 개수입니다.

두 번째 범용적인 방법은 우도 함수를 두 가지 최대화 값의 비율을 통해 사용하는 것입니다: (1) $H_0$ 하에서 가능한 모수 값들에 대한 최댓값, (2) $H_0$ 또는 대립가설 $H_a$가 참일 수 있는 더 넓은 모수 값 집합에 대한 최댓값. $l_0$를 $H_0$ 하에서 최대화된 우도 함수 값이라 하고, $l_1$을 일반적으로 (즉, $H_0 \cup H_a$ 하에서) 최대화된 값이라 합시다. 예를 들어, 모수가 $\beta = (\beta_0, \beta_1)$이고 $H_0: \beta_0 = 0$일 때, $l_1$은 데이터가 발생할 가능성을 가장 높게 만드는 $\hat{\beta}$ 값에서 계산된 우도 함수이고, $l_0$는 $\beta_0=0$이라는 제약 하에 데이터가 발생할 가능성을 가장 높게 만드는 $\hat{\beta}_1$ 값에서 계산된 우도 함수입니다. $l_0$는 제한된 모수 집합에서 최대화를 한 결과이므로, $l_1$은 항상 $l_0$보다 크거나 같습니다.

최대화된 우도들의 비율 $\Lambda = l_0 / l_1$는 1을 넘을 수 없습니다. Wilks (1935, 1938)는 $n \to \infty$일 때, $-2 \log \Lambda$가 귀무가설 하에서 카이제곱 분포로 수렴함을 보였습니다. 자유도(df)는 $H_0 \cup H_a$ 하의 모수 공간 차원과 $H_0$ 하의 모수 공간 차원의 차이와 같습니다. 우도비 검정(likelihood-ratio test) 통계량은 다음과 같습니다.

$$ -2 \log \Lambda = -2 \log(l_0/l_1) = -2(L_0 - L_1) $$

여기서 $L_0$와 $L_1$은 최대화된 로그우도 함수를 나타냅니다.

세 번째 방법은 R. A. Fisher와 C. R. Rao에 의한 스코어 통계량(score statistic)을 사용합니다. 일부 문헌에서 라그랑주 승수 검정(Lagrange multiplier test)이라고도 불리는 이 스코어 검정은 귀무가설 값 $\beta_0$에서의 로그우도 함수 $L(\beta)$의 기울기와 예상 곡률에 기반합니다. 이는 스코어 함수(score function)의 크기를 활용합니다.

$$ u(\beta) = \partial L(\beta) / \partial \beta $$

이 함수를 $\beta_0$에서 계산합니다. $\hat{\beta}$가 $\beta_0$에서 멀수록 $u(\beta_0)$의 절댓값은 커지는 경향이 있습니다. $-E[\partial^2L(\beta)/\partial\beta^2]$를 $\beta_0$에서 계산한 값을 $ι(\beta_0)$로 표기합시다. 스코어 통계량은 $u(\beta_0)$를 그것의 귀무가설 하 표준오차인 $[ι(\beta_0)]^{1/2}$로 나눈 비율입니다. 이는 근사적으로 표준정규 귀무분포를 따릅니다. 카이제곱 형태의 스코어 통계량은 다음과 같습니다.

$$ \frac{[u(\beta_0)]^2}{ι(\beta_0)} = \frac{[\partial L(\beta) / \partial \beta_0]^2}{-E[\partial^2 L(\beta) / \partial \beta_0^2]} $$

여기서 표기법은 $\beta$에 대한 미분을 $\beta_0$에서 계산했음을 나타냅니다. 다변량 모수(multiparameter)의 경우, 스코어 통계량은 $\beta$에 대한 로그우도의 편미분 벡터와 정보 행렬의 역행렬을 이용한 이차 형식(quadratic form)으로 표현되며, 둘 다 $H_0$ 추정값 (즉, $\beta = \beta_0$라 가정한 값)에서 계산됩니다.

그림 1.1은 단변량 사례에 대한 일반적인 로그우도 함수 $L(\beta)$의 그래프를 보여줍니다. 이 그림은 $H_0: \beta = 0$에 대한 세 가지 검정을 설명합니다. 왈드 검정은 ML 추정값 $\hat{\beta}$에서의 $L(\beta)$의 움직임을 사용하며, $(\hat{\beta}/\text{SE})^2$ 형태의 카이제곱 통계량을 가집니다. $\hat{\beta}$의 SE는 $\hat{\beta}$에서의 $L(\beta)$의 곡률에 의존합니다. 스코어 검정은 $\beta=0$에서의 $L(\beta)$의 기울기와 곡률에 기반합니다. 우도비 검정은 $\hat{\beta}$와 $\beta_0=0$ 모두에서의 $L(\beta)$ 정보를 결합합니다. 이는 $\hat{\beta}$에서의 로그우도 값 $L_1$과 $\beta_0=0$에서의 로그우도 값 $L_0$를 카이제곱 통계량 $-2(L_0 - L_1)$을 사용하여 비교합니다. 그림 1.1에서 이 통계량은 $\hat{\beta}$와 0에서의 $L(\beta)$ 값 사이의 수직 거리의 두 배에 해당합니다.

(그림 1.1)


> 그림 1.1 로그우도 함수와 $H_0: \beta = 0$에 대한 세 가지 검정에서 사용되는 정보

1.4.1절은 이항 모수에 대한 추론을 위해 왈드, 우도비, 스코어 검정을 예시합니다. $n \to \infty$일 때, 세 검정은 점근적으로 동등합니다 (Cox and Hinkley 1974, Sec. 9.3). 작거나 중간 정도의 표본 크기에서는, 우도비 검정과 스코어 검정이 왈드 검정보다 보통 더 신뢰할 수 있으며, 실제 오류율이 명목 수준(nominal level)에 더 가깝습니다.

### 1.3.4 검정의 역산을 통한 신뢰구간 구축 (Constructing Confidence Intervals by Inverting Tests)

실제 분석에서는 가설 검정보다 모수에 대한 신뢰구간을 구축하는 것이 더 유용한 정보를 제공합니다. 세 가지 검정 방법 중 어느 것을 사용하든, 검정을 역산하여 신뢰구간을 만들 수 있습니다. 예를 들어, $\beta$에 대한 95% 신뢰구간은 귀무가설 $H_0: \beta = \beta_0$에 대한 검정의 P-값이 0.05를 초과하는 $\beta_0$ 값들의 집합입니다.

$z_\alpha$를 표준정규분포에서 오른쪽 꼬리 확률이 $\alpha$가 되는 z-점수라고 합시다. 이는 해당 분포의 $100(1-\alpha)$ 백분위수입니다. 점근적 정규성에 기반한 $100(1-\alpha)$% 신뢰구간은 $z_{\alpha/2}$를 사용하며, 예를 들어 95% 신뢰구간에서는 $z_{0.025} = 1.96$입니다. 왈드 신뢰구간은 $|\hat{\beta} - \beta_0|/\text{SE} < z_{\alpha/2}$를 만족하는 $\beta_0$의 집합입니다. 이는 다음의 구간을 제공합니다.

$$ \hat{\beta} \pm z_{\alpha/2}(\text{SE}) $$

$\chi^2_{df}(\alpha)$를 자유도 df인 카이제곱 분포의 $100(1-\alpha)$ 백분위수라고 합시다. 우도비에 기반한 신뢰구간은 $-2[L(\beta_0) - L(\hat{\beta})] < \chi^2_1(\alpha)$를 만족하는 $\beta_0$의 집합입니다. [참고: $\chi^2_1(\alpha) = z^2_{\alpha/2}$].

$\hat{\beta}$가 정규분포를 따를 때, 로그우도 함수는 포물선 형태를 가집니다. 범주형 데이터의 작은 표본에서는, $\hat{\beta}$가 정규성에서 멀리 벗어날 수 있으며 로그우도 함수는 대칭적인 포물선 모양에서 크게 벗어날 수 있습니다. 이는 모집단 비율이 0 또는 1에 가까울 때처럼, $\hat{\beta}$가 모수 공간의 경계 근처에 있을 때 중간 또는 큰 표본에서도 발생할 수 있습니다. 이런 경우, $\hat{\beta}$의 점근적 정규성에 기반한 추론은 부적절한 성능을 보일 수 있습니다. 왈드 추론과 우도비 추론의 결과가 현저하게 다른 것은 $\hat{\beta}$의 분포가 정규분포에 가깝지 않을 수 있다는 신호입니다. 1.4.3절의 예시가 이를 보여줍니다.

왈드 신뢰구간은 통계 소프트웨어에서 보고되는 ML 추정값과 표준오차를 사용하여 구성하기 간단하기 때문에 실제로 흔히 사용됩니다.

---

### 핵심 용어 및 개념 설명

이 섹션에서는 최대우도 이론에 기반한 세 가지 핵심적인 가설 검정 방법을 소개합니다. 세 방법 모두 표본이 충분히 크면 결과가 비슷해지지만, 작은 표본에서는 성능 차이를 보입니다.

#### 1. 왈드 검정 (Wald Test)
*   핵심 아이디어: "추정값($\hat{\beta}$)이 귀무가설 값($\beta_0$)으로부터 표준오차(SE)의 몇 배만큼 떨어져 있는가?"를 측정합니다.
*   사용 정보: 로그우도 함수의 꼭대기 지점($\hat{\beta}$)에서의 정보만을 사용합니다. 구체적으로 꼭대기에서의 곡률을 이용해 표준오차(SE)를 계산합니다.
*   장점: 계산이 가장 간단하고 직관적입니다.
*   단점: 표본이 작거나, 추정값이 모수 공간의 경계(예: 비율이 0 또는 1)에 가까울 때 성능이 좋지 않습니다.

#### 2. 우도비 검정 (Likelihood-Ratio Test, LR Test)
*   핵심 아이디어: "귀무가설이 맞다고 가정했을 때의 우도($l_0$)가, 가설에 제약을 두지 않았을 때의 최대 우도($l_1$)에 비해 얼마나 더 작은가?"를 비교합니다.
*   사용 정보: 로그우도 함수의 두 지점, 즉 꼭대기($\hat{\beta}$)에서의 높이($L_1$)와 귀무가설 값($\beta_0$)에서의 높이($L_0$)를 모두 사용합니다. 검정 통계량은 이 높이의 차이($L_1 - L_0$)에 기반합니다. (그림 1.1 참조)
*   장점: 일반적으로 왈드 검정보다 통계적 성능이 더 우수하고 신뢰할 수 있습니다.
*   단점: 두 가지 모델(귀무가설 모델, 대립가설 모델)을 모두 적합시켜야 하므로 계산이 더 복잡할 수 있습니다.

#### 3. 스코어 검정 (Score Test)
*   핵심 아이디어: "만약 귀무가설 값($\beta_0$)이 진짜 모수라면, 그 지점에서 로그우도 함수의 기울기는 0에 가까워야 한다. 실제 데이터로 계산한 기울기가 0에서 얼마나 멀리 떨어져 있는가?"를 측정합니다.
*   사용 정보: 로그우도 함수의 귀무가설 지점($\beta_0$)에서의 정보만을 사용합니다. 구체적으로 그 지점에서의 기울기(score)와 곡률(information)을 이용합니다.
*   장점: 대립가설 모델을 적합시킬 필요가 없어 복잡한 모델에서 계산이 편리할 수 있습니다.
*   단점: 세 검정 중 가장 덜 직관적일 수 있습니다.

#### 검정의 역산을 통한 신뢰구간
이것은 신뢰구간과 가설검정의 근본적인 관계를 이용하는 방법입니다.
*   어떤 모수 값 $\beta_0$를 귀무가설로 설정하여 가설검정을 했을 때, 유의수준 5%에서 기각되지 않았다면, 그 $\beta_0$는 "타당한(plausible) 값"으로 볼 수 있습니다.
*   95% 신뢰구간이란, 이렇게 기각되지 않는 모든 "타당한" $\beta_0$ 값들을 모아 놓은 구간입니다.
*   따라서 왈드 검정을 역산하면 왈드 신뢰구간을, 우도비 검정을 역산하면 우도비 신뢰구간을 얻을 수 있습니다.
