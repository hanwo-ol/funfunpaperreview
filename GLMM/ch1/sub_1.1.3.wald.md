### 왈드 검정의 핵심 아이디어: "얼마나 멀리 떨어져 있는가?"

왈드 검정의 근본적인 질문은 매우 직관적입니다.

> **"우리가 데이터로부터 얻은 최선의 추정치($\hat{\beta}$)가, 우리가 검정하려는 가상의 값($\beta_0$)으로부터 통계적으로 유의미하게 멀리 떨어져 있는가?"**

여기서 '멀리 떨어져 있다'는 것을 판단하기 위한 **"측정 단위" 또는 "잣대"**가 필요한데, 그 역할을 하는 것이 바로 **표준오차(Standard Error, SE)**입니다.

간단한 비유를 들어보겠습니다.
*   어떤 사람의 키를 측정했더니 **185cm**($\hat{\beta}$)였습니다.
*   우리는 이 사람이 "평균 키 집단($H_0$)에 속하는가?"를 검정하고 싶습니다. 이 집단의 평균 키는 **175cm**($\beta_0$)라고 가정합시다.
*   단순히 `185cm - 175cm = 10cm` 차이가 난다고 해서 결론을 내릴 수는 없습니다. 이 10cm가 큰 차이인지 아닌지를 판단할 기준이 필요합니다.
    *   **만약** 측정 오차나 개인 간의 키 편차가 매우 커서, 표준오차(SE)가 **5cm**라면, 10cm 차이는 "표준오차의 2배"만큼 떨어진 것이므로 상당히 의미 있는 차이일 수 있습니다. ($z=10/5=2$)
    *   **만약** 측정 장비가 매우 정밀하고 개인 간 편차도 작아서 표준오차(SE)가 **1cm**라면, 10cm 차이는 "표준오차의 10배"만큼 떨어진 것이므로, 이 사람은 평균 키 집단에 속하지 않을 것이라고 거의 확신할 수 있습니다. ($z=10/1=10$)

왈드 검정은 바로 이 논리를 수학적으로 공식화한 것입니다.

---

### 단일 모수에 대한 왈드 검정 (Univariate Wald Test)

$$ z = \frac{(\hat{\beta} - \beta_0)}{\text{SE}} $$

이 수식의 각 부분을 자세히 살펴보겠습니다.

*   **분자 `($\hat{\beta} - \beta_0$)`**: **관측된 차이 (Observed Difference)**
    *   $\hat{\beta}$: 최대우도(ML) 추정량. 주어진 데이터가 나올 가능성을 가장 높게 만드는 모수 값, 즉 데이터에 기반한 우리의 "최선의 추측"입니다.
    *   $\beta_0$: 귀무가설($H_0$) 하에서의 모수 값. 우리가 "진실이라고 가정"하고 검정하려는 값입니다.
    *   분자는 이 둘 사이의 단순한 거리, 즉 효과의 크기(effect size)를 나타냅니다.

*   **분모 `(SE)`**: **불확실성의 척도 (Measure of Uncertainty)**
    *   이것이 왈드 검정의 핵심 특징입니다. SE는 추정량 $\hat{\beta}$가 표본을 다시 뽑을 때마다 얼마나 변동할 수 있는지를 나타내는 척도입니다. 즉, $\hat{\beta}$의 불확실성 또는 정밀도를 의미합니다.
    *   **"Nonnull" 추정 표준오차**: 텍스트에서 이 부분을 강조하는 이유가 있습니다. 표준오차를 계산하려면 정보량($ι$)을 구해야 하는데, 이 정보량을 계산할 때 **귀무가설 값인 $\beta_0$를 사용하는 것이 아니라, 데이터로부터 추정한 $\hat{\beta}$를 사용**합니다. 이것이 왈드 검정을 스코어 검정(Score Test)과 구분 짓는 가장 중요한 특징입니다.
    *   **논리**: "우리의 추정치 $\hat{\beta}$가 얼마나 불확실한지를 바탕으로, $\hat{\beta}$와 $\beta_0$ 사이의 거리를 평가하겠다"는 접근 방식입니다.

**결과 (`z`)**: 이 z-값은 "우리의 추정치가 귀무가설 값으로부터 표준오차의 몇 배만큼 떨어져 있는가?"를 의미하는 **표준화된 거리(standardized distance)**입니다. 표본이 충분히 크면 이 z-값은 표준정규분포를 따르므로, 우리는 이 값이 얼마나 극단적인지 (P-값)를 쉽게 계산할 수 있습니다.

---

### 여러 모수에 대한 왈드 검정 (Multivariate Wald Test)

만약 검정해야 할 모수가 여러 개(예: 다중 회귀분석의 여러 회귀 계수들)라면, 단순한 나눗셈으로는 충분하지 않습니다. 각 추정량의 불확실성(분산)뿐만 아니라, 추정량들 사이의 관계(공분산)까지 고려해야 합니다.

$$ W = (\hat{\boldsymbol{\beta}} - \boldsymbol{\beta_0})^T [\text{cov}(\hat{\boldsymbol{\beta}})]^{-1} (\hat{\boldsymbol{\beta}} - \boldsymbol{\beta_0}) $$

*   **`($\hat{\boldsymbol{\beta}} - \boldsymbol{\beta_0}$)`**: 이제는 단순한 숫자가 아니라, 각 모수에 대한 차이를 원소로 갖는 **벡터(vector)**입니다.

*   **`[cov($\hat{\boldsymbol{\beta}}$)]⁻¹`**: **일반화된 불확실성의 척도 (Generalized Measure of Uncertainty)**
    *   `cov($\hat{\boldsymbol{\beta}}$)`: 추정량들의 분산-공분산 행렬입니다.
        *   **대각선 원소**: 각 추정량($\hat{\beta_1}, \hat{\beta_2}, ...$)의 분산(Variance), 즉 각자의 불확실성을 나타냅니다.
        *   **비대각선 원소**: 두 추정량 간의 공분산(Covariance), 즉 둘이 함께 어떻게 변하는지를 나타냅니다.
    *   **역행렬(`⁻¹`)**: 이것이 행렬 버전의 "나누기"에 해당합니다. 분산-공분산 행렬의 역행렬은 차이 벡터를 표준화하는 역할을 합니다. 이는 각 모수의 분산뿐만 아니라 모수들 간의 공분산까지 모두 고려하여 전체적인 통계적 거리를 계산하게 해줍니다.

**결과 (`W`)**: 이 복잡한 행렬 계산의 결과는 **단 하나의 숫자**로 나옵니다. 이 숫자 $W$는 추정된 모수 벡터 $\hat{\boldsymbol{\beta}}$가 귀무가설 벡터 $\boldsymbol{\beta_0}$로부터 얼마나 멀리 떨어져 있는지를 나타내는 **종합적인 거리**입니다. 이 $W$ 통계량은 **카이제곱($\chi^2$) 분포**를 따릅니다.

*   **자유도 (df)**: 이때의 자유도는 우리가 동시에 검정하는 모수의 개수와 같습니다. 예를 들어, 3개의 회귀 계수가 모두 0인지를 동시에 검정한다면 자유도는 3이 됩니다.

### 요약 및 결론

*   **왈드 검정**은 데이터로부터 얻은 **추정치($\hat{\beta}$)**와 가설 속의 **기준값($\beta_0$)** 사이의 거리를 측정합니다.
*   이 거리를 측정하는 **"잣대"**로 **표준오차(SE)**를 사용하며, 이 SE는 **데이터로부터 얻은 추정치 $\hat{\beta}$를 기반으로 계산**됩니다. (이것이 핵심!)
*   **단일 모수**의 경우, 이 표준화된 거리는 **z-통계량**이 되고 표준정규분포를 따릅니다.
*   **여러 모수**의 경우, 분산-공분산 행렬의 역행렬을 이용하여 종합적인 거리를 계산하며, 이는 **W-통계량**이 되고 카이제곱 분포를 따릅니다.
*   **장점**: 개념이 직관적이고 계산이 비교적 간단하여, 대부분의 통계 소프트웨어에서 기본적으로 제공하는 검정 방법입니다.
